\documentclass[../thesis]{subfiles}
\graphicspath{{\subfix{../figures/}}}

\begin{document}
\chapter{User Study}\label{ch:evaluation}

\lettrine[lines=3]{\textcolor{Maroon}{D}}{espite} having already done a technical evaluation in \cref{sec:techeval}, it is usually also a good idea to compare new approaches with existing state-of-the-art tools in a user study.
In our case, we want to compare \SEE{}'s \gls{lsp}-generated \glspl{city} with the \glspl{capability} a normal \gls{lsp}-enabled \gls{ide} offers.
For the latter, the Microsoft-developed \gls{ide} \gls{vscode} is a good fit, given that the \glsentrylong{lsp} itself originates here (see \cref{sec:lsp}) and that it still has a deep integration with \gls{lsp}.

First, we will outline the general aim of this study by going over some existing related research, explaining important aspects of \gls{vscode}, and then enumerating our hypotheses.
Next, we will explain the details of the design of the study itself, before analyzing its results with the \participants{} participants in detail.
Finally, we describe some relevant threats to validity.

As a quick aside before we begin, we will frequently use \glspl*{violin} in this chapter to visualize datasets, especially to visually compare two datasets against one another.
A \gls{violin} visualizes the distribution of a collection of data points along with an estimated probability density~\cite{hintze1998}.
The black/white data points are randomly "jittered" along the $x$-axis to make them more differentiable from one another.
A bigger, green point marks the average of the dataset.

To estimate the probability density for the plots, we need to use a non-parametric kernel density estimation (since we do not know which shape the underlying distribution has)---for the kernel itself, we simply use a Gaussian function, but a much more important question is the choice of the bandwidth parameter~\cite{heidenreich2013}.
Here, we use an algorithm by \textcite{sheather1991} that has been improved by \textcite{botev2010a} to be made more performant and handle multimodal distributions better:
The \emph{Improved Sheather--Jones} method, which is a robust choice when one cannot assume normality~\cite{akinshin2020}.
As the algorithm for this method, we use \tt{KDEpy}~\cite{odland2018}, whose implementation of the method is based on \textcite[326--328]{kroese2011}.
A drawback here is that this algorithm does not necessarily converge.
In those cases, we fall back to using Silverman's rule of thumb~\cite{silverman1986}, the implementation of which is integrated into the library we use to draw these plots~\cite{callil-soares2024}.

\section{Plan}\label{sec:plan}
Our main aim here is to answer our second research question that we defined in \cref{sec:goals}:
\begin{displayquote}
	Are \glspl{city} a suitable means to present \gls{lsp} information to developers as compared to \glspl{ide} + tables (on the dimensions of speed, accuracy, and usability)?
\end{displayquote}

To empirically evaluate this research question, we will devise a series of short software engineering related tasks on the real-world software projects \emph{JabRef}\footnote{
	\web{https://github.com/JabRef/jabref}{2024-11-22}
} and \emph{SpotBugs}\footnote{
	\web{https://github.com/spotbugs/spotbugs}{2024-11-22}
}.
Participants then get randomly assigned to either use \SEE{} (along with our implementation from \cref{ch:implementation}) or \gls{vscode} (with an active \gls{ls}).
However, evaluating the supported \glspl{capability} (see \cref{tab:capabilities}) in this way turns out to be quite difficult---for example, how would one evaluate the \emph{Hover} \gls{capability}, let alone features like \glspl{token} which are almost identically implemented across \SEE{} and \gls{vscode}?
For this reason, we will abstain from incorporating the \gls{window}-related \glspl{capability} from \cref{sec:intowindow}.
Limiting ourselves, then, to the \gls{city}-related changes from \cref{sec:intocity}, we have:
\begin{enumerate}
	\item \emph{Diagnostics} being displayed as erosion icons above corresponding nodes.
	      \begin{description}
		      \item[\follows{}] This feature was essentially already evaluated in my bachelor's thesis, albeit with the Axivion Dashboard as a data source instead of \gls{lsp}~\cite{galperin2021,galperin2022}.
	      \end{description}
	\item \emph{Hover} details being displayed when the user hovers the mouse above a node.
	      \begin{description}
		      \item[\follows{}] Since this is used here almost identically as in \glspl{window}, it does not make much sense to compare it against \gls{vscode}.
	      \end{description}
	\item \emph{Go to location}, \emph{references}, and \emph{call/type hierarchy} being used for rendered edges and context menu actions.
	      \begin{description}
		      \item[\follows{}] The context menu actions are not interesting to evaluate for the same reasons as above, though this does not apply to the generated edges.
	      \end{description}
\end{enumerate}

It appears that the only \glspl{capability} that are worth to be evaluated in a user study of this form are actually the ones used in the generation of the \gls{city} in \cref{sec:generate}.
Besides, the bulk of the implementation pertains to the generation of \glspl{city}, so it makes sense to focus on them here.
As a result, the user study is now actually of a form (directly comparing \glspl{city} against \glspl{ide}) that has been researched in previous literature before, so let us take a look at that research first before designing our own study.

\subsection{Existing Research}\label{subsec:research}
Across various bachelor's and master's theses, a number of user studies have been performed about \SEE{}'s usability in various aspects~\cite{davidwagner2020, felixgaebler2021, hannesmasuch2020, kevindoehl2020, maximilianwick2022, michelkrause2024, robertbohnsack2020, rubensmidt2021} as well as about its effectiveness compared to traditional tools~\cite{galperin2021, lennartkipka2020, moritz, nicoweiser2021, rohlfing2024, schramm2022, sulanabubakarov2021, yannisrohloff2021}.
Especially relevant among the latter kind of studies are the three that compare \SEE{} with traditional \glspl{ide}, as that is very close to our own planned evaluation.
Two of these evaluate debugging capabilities that have been implemented into \SEE{}:
\textcite{lennartkipka2020} compares those with Eclipse\footnote{
	\web{https://www.eclipse.org/}{2024-11-17}
}'s debugger, while \textcite{rohlfing2024} uses the debugger of \gls{vscode} as a baseline.
The final one of these studies has \textcite{schramm2022} compare pure \gls{ide} usage (in this case, Microsoft's Visual Studio) with a combination of Visual Studio and \SEE{} in which Visual Studio has a plugin setup that integrates it with \SEE{}.
The result here was a significant improvement for usability and a partial improvement for efficiency in favor of the combination of Visual Studio and \SEE{}.
Almost all of these \SEE{}-related studies also measure its usability in the form of the \gls{sus}, which we will do in our own study, as well.
I have collected the existing scores of those studies in a \gls{violin} in \cref{fig:seesus}.
As a reminder, the big green point marks the average of the dataset.

\pgfplotsset{axis line style={draw=none}}

\begin{figure}
	\centering
	\includegraphics{tikz/seesus.tikz}
	\caption{\Gls{sus} results for \SEE{} across sixteen studies~\cite{davidwagner2020, felixgaebler2021, galperin2021, hannesmasuch2020, kevindoehl2020, lennartkipka2020, maximilianwick2022, michelkrause2024, moritz, nicoweiser2021, robertbohnsack2020, rohlfing2024, rubensmidt2021, schramm2022, sulanabubakarov2021, yannisrohloff2021}.}\label{fig:seesus}
\end{figure}

Outside of \SEE{}, there are a number of other \gls{city} implementations, such as \emph{CodeCity}~\cite{wettel2007} or \emph{Software World}~\cite{knight2000} (see also the overview by \textcite{jeffery2019}).
In their evaluations, these papers often compare different platforms (such as Desktop to VR/AR)~\cite[\eg,][]{merino2017,fittkau2015, merino2018}, but as with the \SEE{}-related theses above, we are most interested in those that have controlled experiments comparing a \gls{city} tool with a traditional \gls{ide}.

One such study was done by \textcite{wettel2011} and compares \emph{CodeCity} against the Eclipse \gls{ide}, with the caveat that participants using Eclipse can also access an Excel spreadsheet of software metrics, as the \gls{city} implementation would otherwise have an unfair advantage.
He based his study on an extensive survey of existing empirical work on software visualization, constructing a "wishlist" of desiderata for such studies~\cite[chapter 7]{wettel2011}.
We will refer back to this wishlist, and to his experiment design in general, in \cref{sec:design} for our own study.
The study was later replicated by \textcite{romano2019} with a subset of tasks.

Similarly, \textcite{mortara2024} supplied tabular data for \gls{ide} users in a comparison against \emph{VariCity}, although here, participants were allowed to choose whatever \gls{ide} they are most comfortable with.
\textcite{mehra2020} gave participants who were using Eclipse an additional 2D graph tool when evaluating the augmented reality \textsc{XRaSE} \gls{city} visualization.
On the other hand, the category of comparative user studies between \glspl{city} and \glspl{ide} without any other helper tools includes ones by \textcite{khaloo2017,galperin2022,lennartkipka2020}.
The results of their experiments, and all others cited here, are listed in the color-coded \cref{tab:compresults}.

\colorlet{LightMaroon}{Maroon!30!white}
\colorlet{LightBlue}{Cyan!30!white}

% Maybe also for non-IDE comp for SEE?
% yellow: mixed, gray: no sig. diff., (light) maroon favor of CC, (light) blue: favor of IDE
% with legend

\newcommand{\reside}[1]{\cellcolor{Blue}\textcolor{White}{#1}}
\newcommand{\rescc}[1]{\cellcolor{Maroon}\textcolor{White}{#1}}
\newcommand{\residel}[1]{\cellcolor{LightBlue}#1}  % e.g., < 50% of tasks
\newcommand{\resccl}[1]{\cellcolor{LightMaroon}#1}
\newcommand{\resmixed}[1]{\cellcolor{Goldenrod}#1}  % Mixed between tasks
\newcommand{\resnone}[1]{\cellcolor{Gray!70!white}No diff.}  % No sig. diff.
% White: not measured
\newcommand{\resna}[1]{\textcolor{Gray}{\textit{N/A}}}

\begin{table}
	\begin{center}
		\caption{Results of various studies comparing \glspl{city} (CC) against \glspl{ide}. $x/y$ indicates an advantage in $x$ out of $y$ tasks or questions.}\label{tab:compresults}
		{
			\footnotesize
			\def\arraystretch{1.3}
			\begin{tabular}{|l|l|l|l|l|l|l|}
				\hline
				\textbf{Study}          & $\bm{n}$ & \textbf{Correctness} & \textbf{Time}                  & \textbf{Usability}             & \textbf{\gls{ide}} & \textbf{\Gls{city}} \\ \hline
				\cite{wettel2011}       & 45       & \rescc{$p = 0.001$}  & \rescc{$p=0.043$}              & \resna{}                       & Eclipse + metrics  & CodeCity            \\ \hline
				\cite{khaloo2017}       & 28       & \resna{}             & \reside{$3/5$ IDE}             & \resccl{$6/20$ CC; $1/20$ IDE} & Visual Studio (VS) & Code Park           \\ \hline
				\cite{romano2019}       & 54       & \rescc{$p= 0.005$}   & \rescc{$p < 0.001\%$}          & \resnone{}                     & Eclipse + metrics  & Code2City           \\ \hline
				\cite{lennartkipka2020} & 10       & \resnone{}           & \resnone{}                     & \resnone{}                     & Eclipse            & \SEE{}              \\ \hline
				\cite{mehra2020}        & 20       & \rescc{$p= 0.005$}   & \resccl{$3/5$ CC; $1/5$ IDE}   & \resccl{Preliminary only}      & Eclipse + 2D graph & \textsc{XRaSE}      \\ \hline
				\cite{galperin2022}     & 20       & \residel{$2/6$ IDE}  & \rescc{$4/6$ CC}               & \reside{$p = 0.028$}           & Axivion Dashboard  & \SEE{}              \\ \hline
				\cite{schramm2022}      & 10       & \resnone{}           & \resccl{$1/3$ CC}              & \rescc{$p = 0.002$}            & VS + Axivion       & VS + \SEE{}         \\ \hline
				\cite{mortara2024}      & 49       & \rescc{$6/11$ CC}    & \resccl{$4/11$ CC; $1/11$ IDE} & \resccl{$4/11$ CC}             & Various + metrics  & VariCity            \\ \hline
			\end{tabular}
		}
		\caption*{\footnotesize Legend: \legendsquare{Maroon} CC advantage, \legendsquare{LightMaroon} Slight CC advantage, \legendsquare{Blue} \Gls{ide} advantage, \mbox{\legendsquare{LightBlue} Slight \gls{ide} advantage}, \mbox{\legendsquare{Gray} No significant difference}, \mbox{{\normalsize $\Box$} Not measured}
		}
	\end{center}
\end{table}


\subsection{VSCode}\label{subsec:vscode}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.95\textwidth]{VSCode}
	\end{center}
	\caption{Screenshot of the main \gls{ui} of \gls{vscode}.}\label{fig:vscode}
\end{figure}

Here, we will very briefly go over \gls{vscode} as the tool that we will compare \SEE{} against.
A screenshot of \gls{vscode} is provided in \cref{fig:vscode}.
On the left side, we can see the filesystem hierarchy of the open project, in the middle is the code itself, and on the right is a minimap as a quick overview of the current file's code.
\gls{vscode} also has an extension system in place with which \glspl{ls} and other enhancements to the editor can be easily installed---for example, we can see a notification in the bottom right prompting the user to install the C\# extension.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.5\textwidth]{VSCode-menu}
	\end{center}
	\caption{Screenshot of (the beginning of) \gls{vscode}'s context menu for code identifiers.}\label{fig:vscode_menu}
\end{figure}

It is also possible to quickly find files with the \keystroke{Ctrl} + \keystroke{P} shortcut, which pops up a menu with a live search through all filenames in the project.
The analogue in \SEE{} is the tree view which was showcased in \cref{sec:intocity}.
Also shown in that chapter was a context menu with various options to make use of the \gls{lsp} "go to location" \glspl{capability}.
\Gls{vscode} has a very similar context menu when right-clicking code identifiers, which is displayed in \cref{fig:vscode_menu}.
Additionally, \gls{vscode} users can also jump to the definition of a symbol by holding down \keystroke{Ctrl} and clicking on that symbol, the same as in \cref{sec:intowindow}.

However, a feature of \SEE{} which \emph{does not} have a clear alternative in \gls{vscode} is the ability to quickly be able to tell certain metrics, such as the number of methods in a file.
In \SEE{}, we could simply visualize that by encoding it as the size of each building, but in \gls{vscode}, participants would need to manually count each method, so to remedy this, we offer a table with such metrics, analogously to Wettel's study.
The table is hosted on Google Spreadsheets\footnote{
	\web{https://docs.google.com/spreadsheets/d/1Z2AQDk2-XeVBB1kAtcpc18mFkPI5ZSsSz\_yOwS4pQ88}{2024-11-20} and \web{https://docs.google.com/spreadsheets/d/1erJZTwYtG-CQfZJPT-zt-chX\_VHL9jLrVfWAWZMFvEo}{2024-11-20}.
} and can be sorted by any column as well as searched.
The script with which the metrics were extracted is attached as \fxwarning*{Attach script in appendix.}{TODO}.

\subsection{Hypotheses}\label{subsec:hypotheses}

To answer \textsf{RQ2} (see \cref{sec:goals}), we would like to know whether there is any significant\footnote{
	Any mention of "significance" in this chapter refers to statistical significance.
} difference between the approaches on the dimensions of \emph{speed}, \emph{correctness}, and \emph{usability}, similar to most other studies mentioned in \cref{subsec:research}.
We will now create more concrete hypotheses for each of these dimensions.

\begin{enumerate}[label=\alph*)]
	\item \textbf{Correctness}: We call the correctness $C_S$ for tasks done in \SEE{} and $C_V$ for tasks done in \gls{vscode}.
	      This will be either a categorical variable with two possible values (\ie, correct or incorrect) or a rational number indicating the percentage of correct answers within a task.
	      \begin{itemize}
		      \item \emph{Null hypothesis} $H_{a_0}$:
		            The correctness when using \SEE{} is the same as when using \gls{vscode}: $C_S = C_V$.
		      \item \emph{Alternative hypothesis} $H_{a_1}$:
		            The correctness when using \SEE{} is different when using \gls{vscode}: $C_S \neq C_V$.
	      \end{itemize}
	\item \textbf{Speed}: We call the time it takes to finish a task $t_S$ for \SEE{} and $t_V$ for \gls{vscode}.
	      \begin{itemize}
		      \item \emph{Null hypothesis} $H_{b_0}$:
		            The time it takes to solve a task when using \SEE{} is the same as when using \gls{vscode}: $t_S = t_V$.
		      \item \emph{Alternative hypothesis} $H_{b_1}$:
		            The time it takes to solve a task when using \SEE{} is different when using \gls{vscode}: $t_S \neq t_V$.
	      \end{itemize}
\end{enumerate}

For the \textbf{usability}, we need to differentiate between the \gls{poststudy} \gls{sus} we use to evaluate the usability of the system as a whole, and the reduced 2-item \gls{posttask} \gls{asq} we use after each task (see \cref{subsec:question}).

\begin{enumerate}[resume,label=\alph*)]
	\item \textbf{\gls{sus}}:
	      We call the \gls{sus} score for \SEE{} $S_S$ and the one for \gls{vscode} $S_V$.
	      \begin{itemize}
		      \item \emph{Null hypothesis} $H_{c_0}$:
		            The \gls{sus} score for \SEE{} is the same as the \gls{sus} score for \gls{vscode}: $S_S = S_V$.
		      \item \emph{Alternative hypothesis} $H_{c_1}$:
		            The \gls{sus} score for \SEE{} is different from the \gls{sus} score for \gls{vscode}: $S_S \neq S_V$.
	      \end{itemize}
	\item \textbf{\gls{asq}}:
	      We need to once again differentiate between the two aspects that the \gls{asq} measures.
	      \begin{enumerate}[label=\roman*)]
		      \item We call the \gls{asq} score for \emph{complexity}\footnote{
			            Note that a higher score here means a lower amount of complexity.
		            } $A^c_S$ for \SEE{} and $A^c_V$ for \gls{vscode}.
		            \begin{itemize}
			            \item \emph{Null hypothesis} $H_{d_0}$:
			                  The \gls{asq} score for complexity when using \SEE{} is the same as when using \gls{vscode}: $A^c_S = A^c_V$
			            \item \emph{Alternative hypothesis} $H_{d_1}$:
			                  The \gls{asq} score for complexity when using \SEE{} is different when using \gls{vscode}: $A^c_S \neq A^c_V$
		            \end{itemize}
		      \item We call the \gls{asq} score for \emph{effort}\footnote{
			            Again, a higher score indicates less required effort.
		            } $A^e_S$ for \SEE{} and $A^e_V$ for \gls{vscode}.
		            \begin{itemize}
			            \item \emph{Null hypothesis} $H_{e_0}$:
			                  The \gls{asq} score for effort when using \SEE{} is the same as when using \gls{vscode}: $A^e_S = A^e_V$
			            \item \emph{Alternative hypothesis} $H_{e_1}$:
			                  The \gls{asq} score for effort when using \SEE{} is different when using \gls{vscode}: $A^e_S \neq A^e_V$
		            \end{itemize}
	      \end{enumerate}
\end{enumerate}

We will use a significance level of $\alpha = 0.05$ for all of our tests, though this will get halved to $0.025$ since we are using two-sided tests.

\section{Design}\label{sec:design}
Since all the hypotheses we just listed compare \SEE{} to \gls{vscode}, the general form of our study should be to have participants solve representative software engineering related tasks, with one group solving tasks in \SEE{} and the other using \gls{vscode}.
There are going to be six tasks, each taking no longer than ten minutes, which we will go over in \cref{subsec:tasks}.
To maximize the number of collected data points, we will have each group use both tools.
Specifically, group $\Psi$ will use \SEE{} for the first three tasks and \gls{vscode} for the last three tasks, while this will be switched around for group $\Omega$.
We will then have $\lfloor \frac{n}{2} \rfloor$ data points per tool for each task, which we can then compare against one another to test for significant differences.
This flow is illustrated in \cref{fig:taskflow}.

We have several constraints for our study.
It should be possible to partake in the study online and asynchronously (\ie, without me needing to be present) to facilitate participation and reduce the \gls{hawthorne} (though this will not completely eliminate it~\cite[\eg][]{evans2010}).
To not overexert participants and thus confound any results, the study should also be of a reasonable length---ideally, not longer than an hour (hence the number of six tasks).
Finally, we cannot assume familiarity with either \SEE{} or \gls{vscode}, so we need to explain the core concepts of each system and verify that the participant understood them before starting the actual tasks.

\newcommand{\cyes}{\textcolor{ForestGreen}{\textbf{[\ding{51}]}}}
\newcommand{\chmm}{\textcolor{BurntOrange}{\textbf{[\textit{?}]}}}
\newcommand{\cno}{\textcolor{Maroon}{\textbf{[\ding{55}]}}}

Additionally, we would like to follow the "wish list" compiled by \textcite[122--124]{wettel2011} (answering each item with yes~\cyes, maybe/partially~\chmm, or no~\cno):
\begin{enumerate}
	\item \textbf{\enquote{Avoid comparing using a technique against not using it.}}
	      We are comparing \gls{vscode} against \SEE{}. \cyes
	\item \textbf{\enquote{Involve participants from industry.}}
	      Roughly half of our participants have reported working on bigger software projects (either within a company or as open-source contributions) for at least 3 years (see \cref{subsec:demographics}), but I have neglected to explicitly ask whether a participant is involved in the industry. \chmm
	\item \textbf{\enquote{Provide a not-so-short tutorial of the experimental tool to the participants.}}
	      We do give a tutorial of each tool to participants, but it only covers the essentials required for the tasks (since we do not want to drag out the participation longer than necessary.) \chmm
	\item \textbf{\enquote{Avoid, whenever possible, to give the tutorial right before the test.}}
	      Unfortunately, we cannot really avoid this.
	      Wettel suggests performing the training a few days before the study, but this is intractable for this study. \cno
	\item \textbf{\enquote{Use the tutorial to cover both the research behind the approach and the implementation.}}
	      The motivation here would be to provide another incentive to participate out of interest in furthering the research.
	      We have left out the research both to keep the participation short and to avoid biasing participants (\eg, by claiming beforehand that developers find \glspl{city} much nicer to use than \glspl{ide}). \cno
	\item \textbf{\enquote{Find a set of relevant tasks.}}
	      Our tasks are representative of real-world activities (see \cref{subsec:tasks}), but some may turn out to have been too easy, as we will see in the analysis in \cref{subsec:correct}. \chmm
	\item \textbf{\enquote{Choose real object systems that are relevant for the tasks.}}
	      We have chosen \emph{SpotBugs} (3.5k GitHub stars, $\approx$ 216 k\gls{loc}) and \emph{JabRef} (3.6k GitHub stars, $\approx$ 179 k\gls{loc}).
	      The former is a fork of the abandoned static analysis tool \emph{FindBugs} that Wettel used for his study, while the latter is a bibliography manager that is well-known enough that some of our participants have heard about or even used it before (see \cref{subsec:demographics}).~\cyes
	\item \textbf{\enquote{Include more than one subject system in the [experiment].}}
	      See first item. \cyes
	\item \textbf{\enquote{Provide the same data to all participants.}}
	      The tasks for both participants (and accompanying data) are identical, and \gls{vscode} participants get access to a table of metrics so that the same data is present. \cyes
	\item \textbf{\enquote{Limit the amount of time allowed for solving each task.}}
	      Integrating a time limit like this into the tool we used for the questionnaire would have been difficult, but the tasks were comparatively simple and participants were aware that their completion time was measured, so we should hopefully have avoided the effects Wettel references here. \chmm
	\item \textbf{\enquote{Provide all the details needed to make the experiment replicable.}}
	      I have included (pseudonymized) participation data, the full definition of the questionnaire, and the analysis script which performed data cleanup and statistical tests. \cyes
	      \fxwarning{Link to appendix here.}
	\item \textbf{\enquote{Report results on individual tasks.}}
	      We are going over each task individually when reporting results in \cref{sec:results}. \cyes
	\item \textbf{\enquote{Take into account the possible wide range of experience level of the participants.}}
	      We are taking a rigorous look at the effects of experience in \cref{subsec:experience}. \cyes
\end{enumerate}

In total, we were able to fulfill 7/13 items on the wish list, with 4/13 being questionably fulfilled and 2/13 not being implemented.
The reasoning behind the unimplemented two were that it would otherwise lengthen the participation time and may strain participants.

\subsection{Questionnaires}\label{subsec:question}
There are three questionnaires that we are going to use for this study:
A demographic questionnaire, a \gls{posttask} questionnaire and a \gls{poststudy} questionnaire, with the last two being used to estimate usability.
We are also going to take a look at \emph{KoboToolbox}, the tool we are using to asynchronously conduct our survey.
An important general consideration is that we will offer our study in both English and German, so any questionnaire we choose (which is usually given in English) needs to have a validated German translation to make results comparable.
This section partially mirrors similar considerations from my bachelor's thesis, which the interested reader can peruse for more details~\cite[35 \psqq]{galperin2021}.
For a comprehensive overview and evaluation of other \gls{poststudy} and \gls{posttask} questionnaires not covered here, see the review by \textcite{hodrien2021}.

\paragraph{Demographics}
We ask each participant various demographic questions to (among other reasons) address the threat to validity of selection bias:
While participants are randomly assigned into groups $\Psi$ and $\Omega$, it is of course possible due to our moderate sample size of $n = \participants$ that there is a significant difference in any independent variable.
A difference like this would then matter if it acts as a confounder for one of the dependent variables---for example, age or experience can have a sizable impact on \gls{sus} scores~\cites[585]{bangor2008}{mclellan2012}.

To catch this, we ask for some properties that could be relevant, namely
gender, age, programming experience, professional programming experience, knowledge of \SEE{}, knowledge of \gls{vscode}, knowledge of JabRef, knowledge of SpotBugs, and experience with 3D video games.
We ask the last question since \SEE{} uses some typical video game paradigms for its controls, so a familiarity with such controls may make \SEE{} more intuitive to use for those people.
Additionally, we ask if the participant has ever used \glspl{ide} before, and if they are able to use the Java programming language.
If the answer to either of those questions is "no," we display a warning telling the participant that this study is not intended for them and may be too difficult (as both JabRef and SpotBugs are Java projects).
We will later filter participations with "no" answers out of our dataset to avoid these problems.

\paragraph{\Gls{posttask}: \gls{asq}}
This questionnaire will be filled out by the participant after each task---since there are six tasks, this will be six times total.
For this reason, we should keep this one short, that is, no more than three questions long, which eliminates questionnaires such as NASA's \gls{tlx}.
There are also the rather unconventional \gls{ume}, which we exclude since it often confuses its users~\cite[1607--1608]{sauro2009b}, or \gls{smeq}, which we exclude because this would be hard to implement in our online questionnaire.
Instead, we choose the \emph{\glsentrylong{asq}}, which consists of three statements for which users give answers on a \gls{likert}:
\begin{enumerate}
	\item \enquote{Overall, I am satisfied with the ease of completing the tasks in this scenario.}
	\item \enquote{Overall, I am satisfied with the amount of time it took to complete the tasks in this scenario.}
	\item \enquote{Overall, I am satisfied with the support information (on-line help, messages, documentation) when completing the tasks.}
\end{enumerate}

We exclude the last question since we neither offer nor want to measure usage of such support information.
However, the rest is ideal for our case:
The \gls{asq} is short, easy to understand, and distinguishes between cognitive and temporal ease---we will call "cognitive ease" \emph{complexity} and "temporal ease" \emph{effort} (as in \cref{subsec:hypotheses}).
The translation by \textcite[32]{roegele2020} will serve as the German version.

\paragraph{\Gls{poststudy}: \gls{sus}}
We will present this questionnaire once after the \SEE{} section and once after the \gls{vscode} section, and will use it to collect a general usability score of each system.
Since the questionnaire is filled out twice, we set an upper limit of twenty questions.
This eliminates both the \gls{sumi} and \gls{quis} from consideration.
Because we need a validated German translation, we can also strike out the English-only \gls{pssuq} as an option.

This leaves the \emph{\glsentrylong{sus}} as a fitting option:
It has a validated German translation~\cite{reinhardt2015}, is the most used \gls{poststudy} questionnaire for this purpose~\cites[1615]{sauro2009}[577]{lewis2018}, and is very well-suited for comparing two systems or interfaces~\cites[195]{peres2013}[590--591]{bangor2008}.
It consists of ten \gls{likert} questions which alternate between positive and negative aspects of the system and returns a score between 0 and 100, representing the system's usability~\cite{brooke1996}.
These questions are collected in \cref{app:susq}.
Existing measured \gls{sus} scores for \SEE{} are given in \cref{fig:seesus}.

\paragraph{KoboToolbox}
The tool with which we manage the survey needs to handle our requirements for it to be feasible to conduct it asynchronously.
Specifically, we need to:
\begin{itemize}
	\item reliably measure the time each task takes to solve,
	\item provide both an English and a German version of the questionnaire,
	\item ask questions with numerical, text-based, selection, and \gls{likert}-based input, and
	\item conditionally show fields or bar the user from continuing (\eg, until the tutorial question is answered correctly) depending on existing input.
\end{itemize}
Among the tools that can handle this for free, \textit{KoboToolbox}\footnote{
	\web{https://www.kobotoolbox.org/}{2024-11-23}
} seems like the most mature and robust option.
It accepts form based on the \gls{xlsform} specification, which makes forms (relatively) easy to create with a spreadsheet editor.
KoboToolbox has also proven itself as a valuable tool in my bachelor's thesis.

Before each task, we tell the user that their time will be measured as soon as they advance to the next page.
Then, we keep a timestamp for each editable field in the task, including a checkbox the user can check to indicate they have finished the task.
Using the set of those timestamps $T$ and the timestamp $t_0$ of when they started the task, the time for the task can then be calculated as $\max T - t_0$.
This also ensures we catch "cheating" in the form of participants editing fields after they have indicated they are finished with the task.
The survey in \gls{xlsform} is linked in \fxwarning*{Link to questionnaire in appendix}{TODO}, and a screenshot of the starting page is shown in \cref{fig:kobo}.

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{Kobo.png}
	\end{center}
	\caption{Starting page of the survey built with KoboToolbox.}\label{fig:kobo}
\end{figure}


To equally partition participants into two groups, we create two versions of the survey, one for group $\Psi$ and one for group $\Omega$.
We then access KoboToolbox's REST API to redirect the participants to version $\Psi$ or $\Omega$---the algorithm we are using is given in \cref{alg:redirect}, or can alternatively be seen in \fxwarning*{Link to script in appendix}{TODO}.
Inviting others to participate then becomes as simple as passing the link to the redirection script around\footnote{
	\url{https://falko.de/master-evaluation}, but this link may not stay up forever.
}.

\begin{algorithm}
	\tikzexternaldisable
	\caption{How participants are redirected to the two versions of the survey.}\label{alg:redirect}
	\begin{algorithmic}[1]
		\small
		\Require{Participant ID $p$ retrieved from cookie in request, or $\varnothing$ if it does not exist.}
		\Ensure{Tuple consisting of the participation ID to be set as a cookie and a survey link.}
		\LComment{Global state: $P$ is an initially empty mapping from IDs to links, $i$ is initially zero.}
		\If{$p \notin P$}
		\If{$p = \varnothing$}
		\State $p = \Call{NewRandomID}{\null}$
		\EndIf
		\State $n_{\Psi}, n_{\Omega} \gets \Call{GetKoboParticipations}{\null}$
		\If{$n_{\Psi} = \varnothing \lor n_{\Omega} = \varnothing$}
		\Comment{API request failed, so just alternate using index $i$.}
		\If{$i = 0$}
		\State $P(p) \gets \Psi$
		\Else
		\State $P(p) \gets \Omega$
		\EndIf
		\State $i \gets (i + 1) \bmod 2$
		\ElsIf{$n_{\Psi} \leq n_{\Omega}$}
		\State $P(p) \gets \Psi$
		\Else
		\State $P(p) \gets \Omega$
		\EndIf
		\EndIf
		\State \Return $(p, P(p))$
	\end{algorithmic}
	\tikzexternalenable
\end{algorithm}

\subsection{Tasks}\label{subsec:tasks}
As explained in \cref{sec:plan}, we cannot feasibly evaluate most implemented \gls{lsp} \glspl{capability} except for the generation of the \gls{city} itself.
This means we are actually comparing a \gls{city} against an \gls{ide}, with \gls{lsp} only playing the role of providing us with those \glspl{city}, for which there are a number of existing experiments that we went over in \cref{subsec:research}.
Thus, we should base our own study design on the existing literature established in that section.
Specifically, out of the similar studies collected in \cref{tab:compresults}, the study by \textcites{wettel2011} (replicated by \textcite{romano2019}) seems most fitting for us:
It compares a desktop \gls{city} implementation against a traditional \gls{ide} along with providing tabular metrics to make the comparison fair.
In addition, the paper provides a great number of details, including detailed task definitions, and a wish list which we went over at the beginning of \cref{sec:design}.

Wettel uses two kinds of tasks~\cite[128--130]{wettel2011}:
Those concerned with program comprehension and those concerned with design quality assessment.
Of these, the latter requires deeper software engineering knowledge that may not be present in all participants, since a large proportion of them are still going to be students.
Thus, we will focus on tasks from the first group:
\begin{enumerate}
	\item \enquote{Locate all the unit test classes of the system and identify the convention (or lack of convention) used by the system’s developers to organize the unit tests.}
	      \begin{description}
		      \item[\follows{}] This task seems like a nice fit to realistically evaluate usage of both tools, so we include it.
		            We will call it \textbf{task $\bm{B}$}.
	      \end{description}
	\item \enquote{Look for the term $T$ in the names of the classes and their attributes and methods, and describe the spread of these classes in the system.}
	      \begin{description}
		      \item[\follows{}] The concept of "spread" would take time to properly introduce and may be misunderstood by some participants.
		            In addition, quantifying the correctness would be hard here, so we exclude this task.
	      \end{description}
	\item \enquote{Evaluate the change impact of class $C$ defined in package $P$, by considering its caller classes. The assessment is done in terms of both intensity and dispersion.}
	      \begin{description}
		      \item[\follows{}] This seems like a complex task that takes time both to properly understand it and then also to execute it, so we exclude it for similar reasons as the previous task.
	      \end{description}
	\item \enquote{Find the three classes with the highest \gls{nom} in the system.}
	      \begin{description}
		      \item[\follows{}] This task also seems simple to understand and probably will not take too long, so we include it.
		            We will call it \textbf{task $\bm{A}$}.
	      \end{description}
\end{enumerate}

Note, however, that none of the tasks we selected above test any edge-related behavior, so we will add one task of our own.
This \textbf{task $\bm{C}$} will be to \enquote{find the \gls{base} for class $c$ in the system.}
Its drawback is that it requires a short explanation of \glspl{base} before the task, but its upsides are that it is both a realistic task and additionally forces participants to have more than a cursory interaction with the edges (specifically, the \tt{Extend} edges\footnote{
	We should also note that the \glspl{city} for this study \emph{only} contain \tt{Extend} edges---otherwise, there would be too many edges for \SEE{} to handle in a performant manner.
}) without having any unfair disadvantage in \gls{vscode}, where participants can navigate up the inheritance tree by repeatedly \keystroke{Ctrl}-clicking on the superclass.

Now we only need to choose a fitting $c$ for both JabRef and SpotBugs, our two object systems.
To make sure the task is not too easy, we choose the class which is deepest in the inheritance tree for both systems.
For JabRef, this is \tt{GenderEditorViewModel} (five levels deep), while for SpotBugs, this is \tt{OptionalReturnNull} (seven levels deep).
This way, we can also evaluate the transitive edge animations we added in \fxwarning*{Where?}{some section}.

We should also mention that, for task $B$, like Wettel, we give multiple choice options for the various kinds of conventions along with brief descriptions to make sure they are understood correctly.
If one of the options is then chosen (\eg, \enquote{Centralized}), users have to give follow-up information (\eg, \enquote{What is the full name of the root package for test classes?}) to make sure the correct answer was not just guessed.
A full visual overview of our study along with its tasks is given in \cref{fig:taskflow}.

\begin{figure}
	\captionsetup{format=plain}
	\centering
	\includegraphics{tikz/taskflow.tikz}
	\caption{Flow of the tasks the participants worked on.\\
		The post-task \gls{asq} questions were asked after each task to gather $A^c$ and $A^e$.
	}\label{fig:taskflow}
\end{figure}


\section{Results}\label{sec:results}
In this section, we can finally report on the results of the study.
We will first go over the course of how the study was conducted before taking a look at the results themselves.
For the latter, we start by analyzing the answers to the demographics questionnaire, and then go on to interpret the dependent variables relevant to our hypotheses, namely, correctness, time, and usability, in that order.
We will then also investigate the role of experience (and some other independent variables) and the influence it had on how tasks were handled.
Finally, we handle the various comments that were left during the study.

As mentioned before, we use a significance level of $\alpha = 0.05$.
We can neither assume normal distributions for our data, nor is it always interval-scaled, so we choose the \gls{mwu} to determine statistically significant differences between either our two groups $\Psi$ and $\Omega$ or between the two tools \SEE{} and \gls{vscode}.
To help the reader quickly identify important results, we put a star ($\bigstar$) in the heading of a paragraph to indicate that it lead to the rejection of a null hypothesis.

\subsection{Study Procedure}\label{subsec:procedure}
Before we started with the actual study, we did a small-scale pilot study with two participants, one of them being this thesis's first reviewer Prof.\ Dr.\ Rainer Koschke.
Through their valuable feedback, I was able to see some issues I had not noticed myself before starting the study, such as a few bugs in \SEE{}, confusion regarding the term \gls{base}, and errors unpacking the prepared compressed builds of \SEE{} and \gls{vscode}\footnote{
	As a sidenote, using prepared builds also prevents any potential problems with pre-installed versions of the tools.
	For example, some plugins of \gls{vscode} might otherwise interfere with our study.
} when using Windows.
I fixed the bugs in \SEE{}, added a tutorial for the \glspl{base} (along with a comprehension question), and added detailed instructions on how to correctly unpack the builds.
There luckily were no other major issues in the actual study after these problems noticed in the pilot study have been ironed out.

There have been \participants participants in total, though we had to exclude one participant from most analyses because he indicated he had no knowledge of Java.
Participants were gained via convenience sampling, that is, I asked fellow students, colleague developers from Axivion, and other acquaintances who had software engineering experience to participate.

\fxwarning{In Appendix, give answer key.}

\subsection{Demographics}\label{subsec:demographics}

First, we want to take a quick look at the demographics of our study.
We also take this opportunity to find any significant differences between the two groups $\Psi$ and $\Omega$, to make sure any results in the dependent variables later on are not just due to such differences.
For this purpose, we define null hypotheses of the form \enquote{Variable $X$ is not different between groups $\Psi$ and $\Omega$}, which we check with a two-sided \gls{mwu}, as we cannot assume normal distributions.
This also allows us to compare data that is only ordinal.

All answers to the demographic questions can be viewed as bar charts in \cref{fig:demobars}.
Two exceptions are the non-categorical variables, namely age and the total time it took participants to finish the study\footnote{This technically does not belong into the "Demographics" category, but it still seems most fitting to include it here rather than in one of the other sections.}, which we are going to go over first.
We have also excluded the question "Have you ever used the program SpotBugs?", as there was only one participant answering "Heard of it," with all others answering "No."
We have also excluded gender from analysis, since we only have one female participant.


\paragraph{Age}
We have a median age of $29$ and an average age of $28.55$ in our sample, suggesting few outliers, which can be confirmed by looking at the violin plots in \cref{fig:dat_age}.
The \gls{mwu} also confirms no differences between the groups ($U = 40.5, p \approx 0.4947$).

\begin{figure}
	\begin{center}
		\violinab{age}{ylabel=Age}{15}{45}{3.1029}{1}{1}
	\end{center}
	\caption{Distribution of age between the two groups.}\label{fig:dat_age}
\end{figure}

\paragraph{Total Time}
The median time it took to complete the whole study was an hour and six minutes, which means we slightly overshot our initial aim of an hour to complete the study.
In addition, the average being at roughly one and a half hours points to there being some significant outliers:
In fact, some participations were longer than 2 hours, with one participant in the $\Omega$ group even taking almost five hours---however, as no single task took anyone longer than twenty minutes (see \cref{subsec:time}), we can conclude that this must be due to breaks in between tasks rather than the participation being actually that long.
The same likely applies to the other participations around the three hour range.
The various times are visualized in \cref{fig:dat_totaltime}, where it also becomes apparent that the two groups had similar total times, which a \gls{mwu} confirms for us ($U = 63, p \approx 0.34470$).

\begin{figure}
	\begin{center}
		\violinab{total-time}{ylabel={Time (in hours)}}{0}{5}{0.1171}{0.106}{1}
	\end{center}
	\caption{Total duration of time in which each participant finished the study.\\
		May include time in which participants took breaks.}\label{fig:dat_totaltime}
\end{figure}

\begin{figure}
	\begin{subfigure}[T]{0.55\textwidth}
		\caption{"What is your highest school or university degree?"\label{fig:degreebar}}
		\barplot{alphabeta-degree}{Fachabitur,Abitur,Bachelor's degree,Master's degree,Doctoral degree}{width=\textwidth, enlarge x limits={0.4}}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.45\textwidth}
		\caption{"How long have you been programming?"\label{fig:programmingbar}}
		\barplot{alphabeta-programming}{Less than 3 years, 3–9 years, 10–19 years}{width=\textwidth, ylabel={},enlarge x limits={0.7}}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.55\textwidth}
		\caption{"Do you know \gls{see}?"\label{fig:knowseebar}}
		\barplot{alphabeta-knowsee}{No, Heard of it, Used it before, Developed parts of it}{width=\textwidth, enlarge x limits={0.5}}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.45\textwidth}
		\caption{"Do you know \gls{vscode}?"\label{fig:knowvsbar}}
		\barplot{alphabeta-knowvs}{No, Heard of it, Used it before, Is my main IDE}{width=\textwidth, ylabel={}, enlarge x limits={1}}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.55\textwidth}
		\caption{"Have you ever used the program JabRef?"\label{fig:knowjabrefbar}}
		\barplot{alphabeta-knowjabref}{No, Heard of it, Used it before, Developed parts of it}{width=\textwidth, enlarge x limits={0.5}}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.45\textwidth}
		\caption{"Do you play 3D video games for desktops?"\label{fig:knowgamebar}}
		\barplot{alphabeta-knowgame}{I never played, I barely play, I play a lot}{width=\textwidth, ylabel={}, enlarge x limits={0.7}}
	\end{subfigure}
	\caption{Number of respective answers to various demographic questions.\\
		Group \textcolor{Maroon}{$\Psi$ is in red}, and group \textcolor{Gray!50!black}{$\Omega$ is in gray}.}\label{fig:demobars}
\end{figure}

\paragraph{Degree}
Most participants had a Bachelor's degree (this is also the median), with some Abitur qualifications, Master's degrees, and one person with a doctoral degree (see \cref{fig:degreebar}).
The \gls{mwu} reveals no significant differences between $\Psi$ and $\Omega$ ($U = 57.5, p \approx 0.5693$).

\paragraph{$\bigstar$ Programming Experience}
Both the median and modal programming experience is 3--9 years.
However, we can see that the only people with 10--19 years of experience are in group $\Psi$, and the \gls{mwu} indeed confirms a significant difference here ($U = 77, p \approx 0.0214$).
It is unclear how this could have happened except coincidentally, as participants were always alternatingly assigned to either group $\Psi$ and $\Omega$.
Still, we should keep this difference in mind when moving on to the analysis of dependent variables.

\paragraph{$\bigstar$ Experience on Bigger Software Projects}

\begin{wrapfigure}{L}{0.5\textwidth}
	\centering
	\barplot{alphabeta-opensource}{Not yet, Less than 3 years, 3–9 years}{width=0.5\textwidth,ymax=10,height=5.2cm,enlarge x limits={0.6}}
	\caption{"How long have you been programming on bigger software projects (\eg, within a company, or open-source projects)?"}\label{fig:opensourcebar}
\end{wrapfigure}

We also asked participants for experience with larger software projects, such as within companies or on open-source projects.
Here, all but one participant have been working on bigger software projects, but the split between the "Less than 3 years" and "3--9 years" categories are inverted between groups $\Psi$ and $\Omega$, which can also be seen in \cref{fig:opensourcebar}.
The \gls{mwu} again confirms a significant difference ($U = 80.5, p \approx 0.0105$).

\paragraph{Experience with \SEE{}}
The clear majority of participants (eleven people) have developed on \SEE{} before, as can be seen in \cref{fig:knowseebar}, which can be attributed to the fact that one major group of people I asked to participate are the students who are working on \SEE{} in a professional or academic capacity.
We can also see a qualitative difference between the two groups:
Group $\Omega$ contains the only people who have answered "No", while group $\Psi$ contains the only people who have answered "I heard of it" and "I used it before".
However, this difference is not significant ($U = 42.5, p \approx 0.5598$).

\paragraph{Experience with \gls{vscode}}
Every single participant has used \gls{vscode} before, with six people even using it as their main \gls{ide}.
We can assume that most participants thus have more experience with \gls{vscode} than \SEE{}, which may bias our results somewhat---we try to investigate this further in \cref{subsec:experience,sec:threats}.
\Cref{fig:knowvsbar} shows the groups to be quite similar, and indeed, there is no significant difference here ($U = 55, p \approx 0.6809$).

\paragraph{Experience with JabRef}
Most participants in either group have not heard of JabRef before, but in contrast to SpotBugs, some have actually used the bibliography manager before, with one participant in group $\Psi$ even having developed parts of it (see \cref{fig:knowjabrefbar}).
Again, there is no significant difference between the two groups ($U = 58, p \approx 0.5041$).

\paragraph{Experience with Video Games}
A clear majority of sixteen participants reported that they play a lot of video games (as can be seen in \cref{fig:knowgamebar}), with only two responding that they barely play and one stating that they never played video games before.
There is no significant difference we need to be aware of ($U = 46, p \approx 0.6701$) here, either.

In summary, the only significant differences between the two groups that could cause problems in our analysis are the programming experience in general and the programming experience for bigger projects, both of which indicate significant differences insofar that group $\Psi$ apparently contains more experienced programmers.
We will investigate the effects of this in more detail in \cref{subsec:experience}.

\subsection{Correctness}\label{subsec:correct}
To evaluate the correctness of the various answers, I wrote a script which showed me each answer and prompted me to say whether this answer was correct or incorrect, while I used the previously created answer key (see {TODO}) as a base.
This allowed me to catch misspellings or unusual formats\footnote{For example, some participants also entered the \gls{nom} along with the class name for task $A$.} and still mark the answers as correct.
The results of which answers I marked as correct are attached as {TODO}, while the script used to do so is part of the general analysis script in {TODO}.
\fxwarning{Attach and link answer key, correctness answers, script in appendix}

It does not make much sense to use \glspl{violin} here, as there are in most cases only two possible values here:
The participants were either correct or incorrect in their answer to the task.
Even for task $A$, where three answers had to be given, we only have at most three possible values in practice.
For this reason, we are using bar graphs again, which are collected in \cref{fig:correctness} along with the respective results of the statistical tests.
I also need to note that, while task $A$ can be analyzed with the \gls{mwu}, tasks $B$ and $C$ with their binary results are much better suited for \gls{fisherexact}, which takes a $2 \times 2$ contingency table as input.
We chose this test instead of the more frequently used $\chi^2$ test~\cite{pearson1900} because it is (as its name implies) more exact, and thus works better with smaller sample sizes~\cite{fisher1922}, whereas its downside is a more involved computation, which we do not need to worry about here.

\begin{figure}
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Achieved correctness for task $A_1$.\\
			($U = 46, p \approx 0.939$)
			\label{fig:a1c}}
		\barcplot{seevs-a1-c}{width=\textwidth,ylabel={Number of participants},xticklabels={None correct, One correct, All correct},xtick={0,1,3}}{1}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Achieved correctness for task $A_2$.\\
			($U = 50, p \approx 0.3428$)\label{fig:a2c}}
		\barcplot{seevs-a4-c}{width=\textwidth,ylabel={},xticklabels={None correct, All correct},xtick={0,3}}{2}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Achieved correctness for task $B_1$.\\
			($U = 0.5, p \approx 0.65$)\label{fig:b1c}}
		\barcplot{seevs-a2-c}{width=\textwidth,ylabel={Number of participants},xticklabels={Wrong, Correct},xtick={0,1}}{1}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Achieved correctness for task $B_2$.\\
			($U = 0.3, p \approx 0.3698$)\label{fig:b2c}}
		\barcplot{seevs-a5-c}{width=\textwidth,ylabel={},xticklabels={Wrong, Correct},xtick={0,1}}{2}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Achieved correctness for task $C_1$.\\
			($U = 0, p = 1$)\label{fig:c1c}}
		\barcplot{seevs-a3-c}{width=\textwidth,ylabel={Number of participants},xticklabels={Wrong, Correct},xtick={0,1}}{1}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Achieved correctness for task $C_2$.\\
			($\text{no differences, } U \text{ undefined}; p = 1$)\label{fig:c2c}}
		\barcplot{seevs-a6-c}{width=\textwidth,ylabel={},xticklabels={Wrong, Correct},xtick={0,1}}{2}
	\end{subfigure}
	\caption{Correctness achieved in the various tasks, compared across the two systems.\\
		Correctness when \textcolor{Maroon}{using SEE is in red}, and when \textcolor{Gray!50!black}{using VSCode is in gray}.}\label{fig:correctness}
\end{figure}

We can make several observations here:
First, performance compared across the two object systems JabRef and SpotBugs is remarkably similar within tasks, which tells us that neither of the two systems was harder to analyze than the other under our tasks.
We can also see a slight difference across subject systems in task $B$, where participants gave slightly more correct answers when using \gls{vscode} for $B_1$ and when using \SEE{} for $B_2$, but none of the $p$ values come close to our significance level, meaning that the choice of subject system did not affect the correctness for these tasks.
Finally, we can tell that tasks $A$ and $C$ were easy (with only one or two participants per task making mistakes), while task $B$ was seemingly hard (with the wrong/correct divide being closer to 50\%).

As a reminder, task $B$ was about determining how unit tests were organized in the system.
For SpotBugs, there actually were no unit tests under the root package we included---there were some files with \tt{Test} in their name, but as SpotBugs is a static analysis tool, these were actually about detecting and handling tests for the projects that SpotBugs analyzes.
The only class that could be reasonably construed as a test was \proptt{TestDataflowAnalysis}, so we allowed both "none" and "dispersed" as answers, though the latter only if \proptt{TestDataflowAnalysis} was given as an example.
The most common error here was participants mistaking the aforementioned test detectors by SpotBugs as unit test classes \emph{for} SpotBugs (either giving them as a "centralized" or "dispersed" example), while the second-most common type of wrong answer were "other" answers which consisted of confused explanations of the system in the free text field.

For JabRef, unit tests were all centralized under the \tt{src.test} package, so I had expected there to be less issues here for task $B$ than with SpotBugs.
\Cref{fig:b1c,fig:b2c} prove this assumption wrong.
The most common (and actually only) type of error was to answer "dispersed" and then give one or more test classes under the centralized test package hierarchy as examples.
I am not sure what went wrong here.
While I have provided explanations of the "dispersed" and "centralized" conventions, perhaps this was still misunderstood by participants (\eg, maybe because the test package hierarchy mirrors the main package hierarchy, participants thought that the "dispersed" term applies here).
Another possible explanation is that participants simply missed the fact that the test file they were looking at (which they likely arrived at by searching for the term "Test") was actually in the \tt{src.test} package instead of \tt{src.main}.
Still, it is interesting that this happened with both \gls{vscode} and \SEE{}.

In conclusion, we cannot reject $H_{a_0}$ at all, and thus keep assuming that $C_S = C_V$.

\subsection{$\bigstar$ Time}\label{subsec:time}
As mentioned before, we calculated the time it took to complete a task using the set of timestamps $T$ and the starting timestamp $t_0$ as $\hat{t} = \max T - t_0$.
This ensures that the actual time is no higher than $\hat{t}$, but it does not catch the opposite:
It is possible that participants were, for example, distracted and had to stop solving the task to attend some other matter, which could explain outliers like the twenty minute participation time for one participant in task $A_1$ (see \cref{fig:a1t}).
Still, while there are some such outliers, the measured times were relatively consistent, so this method should have been accurate enough for our purposes.
While the \glspl{violin} in \cref{fig:time} include all data points, for the \glspl{mwu} we exclude data points belonging to incorrect answers for the respective tasks (as we do not want to count quick but wrong solutions).

\begin{figure}
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Time taken for task $A_1$. Excluded a \SEE{} outlier that took 20 minutes.
			($U = 47, p \approx 0.3213$)
			\label{fig:a1t}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a1t.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Time taken for task $A_2$.\\
			($U = 19, p \approx 0.0676$)\label{fig:a2t}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a4t.tikz}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Time taken for task $B_1$.\\
			($U = 5, p \approx 0.08225$)\label{fig:b1t}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a2t.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Time taken for task $B_2$. Excluded a \gls{vscode} outlier that took 16 minutes.
			($U = 15, p \approx 0.6095$)\label{fig:b2t}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a5t.tikz}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Time taken for task $C_1$.\\
			($\bigstar\ U = 77, p = 0.0015$)\label{fig:c1t}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a3t.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Time taken for task $C_2$. Excluded a \SEE{} outlier that took 8 minutes.
			($\bigstar\ U = 17, p = 0.0247$)\label{fig:c2t}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a6t.tikz}
	\end{subfigure}
	\caption{Time that it took participants to solve the tasks, compared across the two systems.
		Outsiders are excluded by cutting off the Y-axis---they are still included in the average.}\label{fig:time}
\end{figure}

We can see a slight, but non-significant advantage for \gls{vscode} for task $A$ (\cref{fig:a1t,fig:a2t}), where the classes with the highest \gls{nom} had to be identified.
\gls{vscode} users were allowed to use a table that could be sorted by exactly this metric, while \SEE{} users had to glean this information by inspecting the size or color of the buildings in the \gls{city}.
The former made this task very simple and quick to solve, probably even more so than the visual method provided by \SEE{}.
In task $B$, by contrast, we see (\cref{fig:b1t,fig:b2t}) a slight and again non-significant advantage for \SEE{}.
This was the task about identifying the way that unit tests were organized.
Perhaps \SEE{} made the structure of the package hierarchy more immediately visible, which would have especially helped in task $B_2$ (where we do see a bigger margin) where all tests were in a separate hierarchy---in \gls{vscode}, this would have just been a path at the top of the \gls{ide} indicating where the file belongs, while for \SEE{} it would be immediately apparent due to the node's location that the class belongs to a certain package.

The only actual significant difference lies in task $C$ (\cref{fig:c1t,fig:c2t}) for both object systems.
Here, participants using \gls{vscode} outperformed those using \SEE{}, with an especially clear difference for task $C_1$, where we have a $p$-value of ca.\ $0.1\%$.
This was the task about finding a \gls{base} for a given class.
In \gls{vscode}, this was very simple:
All that participants needed to do was to keep \keystroke{Ctrl}-clicking on the superclass until they eventually reach a class without any parent.
In \SEE{}, this was similarly simple, but required more interaction with the 3D city.
The transitive edge animation does pretty quickly point to the \gls{base} of the hovered node, but especially for SpotBugs (see \cref{fig:c1t} for the more pronounced difference) the final edge pointed to a relatively dense and small cluster of nodes, so users would have to zoom in and move the city around further before being able to clearly tell which node the edge targets.
This forced participants to become more familiar with \SEE{}'s controls compared to \gls{vscode}'s very simple repeated clicking, so this is my primary guess as to where the time difference comes from.
Some of the comments that we got in \cref{subsec:comments} seem to support this interpretation.

While four out of the six tasks yielded no significant differences, two of them point to \gls{vscode} increasing the participants' speed, so we will reject $H_{b_0}$ and accept $H_{b_1}$ instead, specifically, $t_V < t_S$.

\subsection{$\bigstar$ Usability}
We have measured the usability in two ways:
With the \gls{asq} after each task (six times total), which we will examine first, and with the \gls{sus} after each system (twice total), which we will examine afterwards.

\paragraph{\gls{asq}: Complexity}
The \gls{asq} consists of two questions, the first of which is about the "cognitive" complexity or difficulty of solving the task---this is the factor we will examine here.
Comparisons of this factor between the two systems are visualized in \cref{fig:asqc}.
Note that the values are \gls{likert} responses to the question given in \cref{subsec:question}, meaning that \emph{lower} scores correspond to \emph{higher} complexity.

\begin{figure}
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived complexity for task $A_1$.\\
			($U = 42, p \approx 0.82496$)
			\label{fig:a1ac}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a1ac.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived complexity for task $A_2$.\\
			($U = 66, p \approx 0.08332$)\label{fig:a2ac}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a4ac.tikz}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived complexity for task $B_1$.\\
			($U = 58.5, p \approx 0.27923$)\label{fig:b1ac}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a2ac.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived complexity for task $B_2$.\\
			($U = 42.5, p \approx 0.86514$)\label{fig:b2ac}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a5ac.tikz}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived complexity for task $C_1$.\\
			($U = 21.5, p \approx 0.05357$)\label{fig:c1ac}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a3ac.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived complexity for task $C_2$.\\
			($U = 59.5, p \approx 0.2005$)\label{fig:c2ac}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a6ac.tikz}
	\end{subfigure}
	\caption{Perceived complexity for each system as measured by the \gls{asq} for each task.\\
		\textbf{A higher number means an easier perception of the task, \ie, \emph{lower} complexity.}}\label{fig:asqc}
\end{figure}

\Cref{fig:a1ac,fig:b1ac,fig:b2ac,fig:c2ac} for tasks $A_1$, $B_1$, $B_2$, and $C_2$, respectively, show only negligible or even close to no differences between the two systems.
The only differences that come at least within an order of magnitude of our significance level of $\frac{\alpha}{2} = 0.025$ are the results for tasks $A_2$ and $C_1$, but even those are due to one or two outliers with very high complexity on the side of \SEE{} without which their $p$-value comes closer to those of the other tasks.

Thus, from both a qualitative view (\ie, by looking at the \glspl{violin}) and a quantitative view (\ie, through the \glspl{mwu}) we cannot draw any conclusions that are backed by statistically significant differences on the perceived complexity here and keep the null hypothesis $H_{d_0}$, that is, we keep the assumption that $A^c_V = A^c_S$.

\paragraph{$\bigstar$ \gls{asq}: Effort}
The second factor measured by the \gls{asq} is the "temporal" effort, that is, whether participants were happy with the amount of time it took them to solve a given task.
As with the previous section, the comparisons shown in \cref{fig:asqt} are of a form where, the \emph{higher} the score is, the \emph{lower} the perceived effort is.

\begin{figure}
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived effort for task $A_1$.\\
			($U = 42, p \approx 0.82956$)
			\label{fig:a1at}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a1at.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived effort for task $A_2$.\\
			($\bigstar\ U = 78.5, p \approx 0.00531$)\label{fig:a2at}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a4at.tikz}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived effort for task $B_1$.\\
			($U = 45.5, p = 1$)\label{fig:b1at}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a2at.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived effort for task $B_2$.\\
			($U = 33, p \approx 0.33402$)\label{fig:b2at}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a5at.tikz}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived effort for task $C_1$.\\
			($\bigstar\ U = 15, p \approx 0.0142$)\label{fig:c1at}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a3at.tikz}
	\end{subfigure}\hfill
	\begin{subfigure}[T]{0.5\textwidth}
		\caption{Perceived effort for task $C_2$.\\
			($U = 52, p \approx 0.55359$)\label{fig:c2at}}
		\includegraphics[width=\textwidth,height=6cm]{tikz/a6at.tikz}
	\end{subfigure}
	\caption{Perceived effort for each system as measured by the \gls{asq} for each task.\\
		\textbf{A higher number means an easier perception of the task, \ie, \emph{lower} effort.}}\label{fig:asqt}
\end{figure}

Interestingly, the tasks with the smallest difference in answers to this questions are once again tasks $A_1$, $B_1$, $B_2$, and $C_2$ in \cref{fig:a1at,fig:b1at,fig:b2at,fig:c2at}.
The remaining two \cref{fig:a2at,fig:c1at} belonging to tasks $A_2$ and $C_1$, however, actually produce a statistically significant result here, both times in favor of \gls{vscode}, where participants felt they could solve the task faster than those using \SEE{}.
A quick comparison against \cref{fig:time} in \cref{subsec:time} reveals that they are right:
In task $C_1$, participants were significantly faster when using \gls{vscode}, and while there was no significant difference for task $A_2$, participants were still faster on average with \gls{vscode}.

It is slightly puzzling, though, that no such difference in the perceived effort exists for task $C_2$, where \cref{fig:c2t} \emph{does} show a significant difference.
Looking again at the result of the significance test, the $p$-value of $0.0247$ is extremely close to our significance level, so perhaps the difference is not as pronounced, although in that case I would have expected the \gls{asq} effort for task $A_2$ to also have a noticeable difference.
Maybe there is a difference between perceived versus actual time taken for the $A$ task, in that it feels more strenuous or at least slower than the $C$ task (\eg, maybe it is more interesting to follow the transitive hops of the edge around the city than to look for big buildings and enter them into a table).

Similar to \cref{subsec:time}, four of the six tests did not have significant differences, but two of them did in favor of \gls{vscode}, so we will reject $H^{e_0}$ and accept $H^{e_1}$ instead with $A^e_V > A^e_S$.

\paragraph{$\bigstar$ \gls{sus}}
Finally, the \glsentrylong{sus} measures the usability of a system as a whole with ten questions.
To map a set of answers onto a score from 0--100, we apply the formula by \textcite{brooke1996}, that is, $2.5 \cdot (20 + \sum\limits_{i = 1}^{10} (-1)^{i+1} \cdot s_i)$, where $s_i$ is the answer to the $i$-th \gls{sus} question on a \gls{likert} from 0--4.
The alternation introduced by the factor $(-1)^{i+1}$ exists due to the fact that even-numbered questions are inverted phrasings of the odd-numbered questions.
\Cref{fig:sus} exhibits the difference in measured \gls{sus} scores between \SEE{} and \gls{vscode}.
We have 38 data points here because participants were asked to rate both systems.

\begin{figure}
	\center
	\violinsus
	\caption{Comparisons between measured \gls{sus} scores for \SEE{} and \gls{vscode}.}\label{fig:sus}
\end{figure}

As one might guess from the star in the heading, the difference here is significant when we apply the \gls{mwu}, specifically in favor of \gls{vscode} ($U = 114.5, p \approx 0.02116$).
The average \gls{sus} score for \SEE{} is $69.5$, with a median of $68.75$, while the \gls{sus} score for \gls{vscode} was on average $80.5$, with a median of $82.5$.
Our measured score for \SEE{} falls in line with the average for \SEE{} established from other experiments (see~\cref{fig:seesus}), and its difference to a traditional tool also replicates the results of the study for my bachelor's thesis~\cite{galperin2022}.
There may be multiple reasons why \SEE{} does worse than \gls{vscode} here:
As a research project, it is less polished than the professionally developed \gls{vscode}, it uses paradigms and controls that users may be less familiar with than those in a traditional \gls{ide}, or there may be specific grievances users had with \SEE{}.
We can at least cast light on the last of these explanations by examining the feedback participants have left about \SEE{}, which we will do in \cref{subsec:comments}.

In summary, we can reject $H_{c_0}$ and accept the alternative hypothesis $H_{c_1}$, specifically, that $S_V > S_S$.

\subsection{The Effects of Experience}\label{subsec:experience}
As noted before, we now want to see if there is a correlation between any independent variables (especially ones related to experience) and any dependent variables (such as correctness).
One of the reasons we do this is simple scientific interest, but another is to check whether any significant differences between groups $\Psi$ and $\Omega$ that we uncovered in \cref{subsec:demographics} actually have a non-negligible bearing on the results of the study.

There is one problem we need to handle first.
Assuming that we create a null hypothesis of the form "independent variable $X$ is not correlated to dependent variable $Y$ for task $Z_i$," for each possible $X$, $Y$, $Z$, and $i$, we would create $9 \cdot (4 \cdot 3 \cdot 2 + 2) = 234$\footnote{The $+2$ is due to the \gls{sus}, which is asked twice.} null hypotheses and perform a corresponding number of statistical tests.
At a significance level of $\alpha = 0.05$, we have a $5\%$ chance of a false positive.
Hence, for this many tests, we are virtually certain to hit at least one---in fact, we should expect around $12$ (\ie, $234 \cdot 0.05$) of them.
This is know as the \gls{multiplecomp}.
Since we do not really care that much about the correlation for each individual task, we can at least reduce this problem somewhat by aggregating along the two subject systems, that is, by averaging results for the first three tasks and then for the last three tasks, to get a single dependent variable per system instead of three.
Still, this leaves us with $90$ tests, where we can expect roughly 5 false positives.

There are a few ways to solve this, one of the most famous being the Bonferroni correction, which simply divides the significance level by the number of hypotheses~\cite[66 \psq]{miller1981}.
However, this method of controlling the \gls{fwer} is known to be very conservative---with our moderate sample size of $n=\participants$ we would prefer a method less likely to result in false negatives.
Luckily, such a tool exists in the procedure by \textcite{benjamini1995} to control the \gls{fdr}.
Since our data points here might not be fully independent, we choose the variation by \textcite{benjamini2001} and fix the \gls{fdr} at our usual $\alpha$ of $0.05$.
We designate the "original" $p$-value (\ie, the one before fixing the \gls{multiplecomp}) as $\xcancel{p}$.

For the correlations themselves, we follow the recommendations by \textcite[157,159]{khamis2008} and use Kendall's coefficient of rank correlation $\tau_b$ for comparisons with ordinal independent variables~\cite{kendall1938, kendall1945}, and Spearman's rank correlation coefficient $r$\footnote{
	We could have also used Pearson's correlation coefficient $r$~\cite{bravais1844, pearson1895}, but Spearman's $r$ seems more fitting due to our dataset including some outliers.
} for comparisons with continuous independent variables~\cite{spearman1904} (since all our dependent variables, at least in aggregated form, are continuous).

\begin{figure}
	\centering
	\includegraphics{tikz/corr.tikz}
	\caption{Correlations between independent and dependent variables.\\
		Dependent variables for \SEE{} are marked in \textcolor{Maroon}{red} and those for \gls{vscode} in \textcolor{Gray!50!black}{gray}.}\label{fig:corr}
\end{figure}

A matrix of correlations between the independent and dependent variables is given in \cref{fig:corr}.
The size of the circles corresponds to the strength of the correlation, while the color indicates its direction in addition to strength.
We can see that no particularly dark colors, and thus no particularly strong correlations are present.
Indeed, the only correlations that would even be normally classified as "moderate"~\cite{akoglu2018} (these also turn out to be the only statistically significant results \emph{before} applying the \gls{fdr} correction) are the following two negative correlations:
\begin{itemize}
	\item \textbf{Experience with bigger software projects} and the \textbf{\gls{sus} for \gls{vscode}} correlate negatively with $\tau_b \approx -0.4225$ ($\xcancel{p} \approx 0.0313, p \approx 1$).
	      \begin{itemize}
		      \item This is a very surprising result to me.
		            I would have expected more experience on bigger software projects to have led to more familiarity with tools like \gls{vscode} and hence to higher usability ratings.
		            If we want to speculate, maybe very experienced developers have more specific "tastes", such as a heavily customized editor, leading to less enjoyment when they have to use the normal \gls{vscode}, but this does not really ring true, personally.
	      \end{itemize}
	\item \textbf{Experience with \gls{vscode}} and the \textbf{\gls{sus} for \SEE{}} correlate negatively with $\tau_b \approx -0.4523$ ($\xcancel{p} \approx 0.0247, p \approx 1$).
	      \begin{itemize}
		      \item This result at least seems to make intuitive sense---developers used to \gls{vscode} may feel less productive when switching to a very new environment like \SEE{}.
	      \end{itemize}
\end{itemize}

However, we cannot put too much stock in the speculation given above, since neither of the two \gls{fdr}-adjusted $p$-values are anywhere near below our significance level.
Thus, in total, we cannot make out any significant correlation between independent and dependent variables here, which has the upside that we need not worry as much about any of the differences in independent variables from \cref{subsec:experience} biasing our results.

\subsection{Comments}\label{subsec:comments}

\newcommand{\answer}[1]{\begin{description}\item[\follows{}]{#1}\end{description}}
\newcommand*{\agree}{%
	\scalebox{-1}[1]{%
		\begingroup
		\sbox0{Ag}%
		\raisebox{-\dp0}{%
			\includegraphics[{%
						height=\dimexpr\dp0+\ht0\relax,%
					}]{Symbol_thumbs_up-crop.pdf}%
		}%
		\endgroup
	}%
}

Here, we shall go over the comments that participants have left in the free text fields.
There has been one such field for feedback about \SEE{}, one for feedback about \gls{vscode}, and one for general comments.
I will group the comments together and rephrase them in a more general and direct way to eliminate duplicates, make this easier to read, and to preserve the anonymity of the participants.
The number of times a type of comment has been left is indicated by a number in brackets after the description, if this number is greater than one.
My responses to comments are indicated by the "\follows{}" symbol, while simple agreement without any further elaboration is indicated by the "\agree" symbol\footnote{
	A missing "\agree" symbol does not necessarily indicate disagreement on my part, some comments (\eg, "\gls{vscode} was great to use") are just of a form where agreement does not make much sense as a response.
}.
\fxnote{Should I move this into an appendix instead of listing the comments here?}

\paragraph{\SEE{}}
Since this is where most of the comments were left, I will group these comments into three categories.

\begin{itemize}
	\item \textbf{Feature/change requests}:
	      \begin{itemize}
		      \item A copy-paste feature for text in \SEE{} (including in \glspl{window}) would have been useful. $\bm{[3\times]}$ \agree
		      \item It should be possible to sort all classes in the tree view independent of the tree structure. $\bm{[2\times]}$
		            \answer{This use-case is already planned as issue \href{https://github.com/uni-bremen-agst/SEE/issues/680}{\proptt{\#680}}.}
		      \item The \gls{fov} should be increased.
		            \answer{This is easy to implement, and should probably even be adjustable in-game instead of being a fixed value.}
		      \item After zooming in and zooming out again, it is hard to move the \gls{city} back to its original spot.
		            The \gls{city} should ideally be fixed in place when zooming. \agree{}
		      \item There should be a more obvious function to highlight the superclass instead of just the edges.
		            \answer{This function already exists via the context menu, but was not included in the explanatory video.}
		      \item It would be useful to have the feature to directly navigate to the \gls{base} instead of having to go from one parent to the next.
		            \answer{I agree when talking about \SEE{} as it is normally used, but for this study, the intent was to have a non-trivial task that required moderate interaction with the \gls{city} environment.}
		      \item File paths should have been shown more prominently.
		            \answer{There should at least be an option to include this information in the hover popup.
			            Showing paths for every node in the city would overcrowd it a bit.}
		      \item The "show in city" effect should stop more quickly. \agree
		      \item A key combination to trigger edges for a given node would be useful to quickly navigate using edges.
		            \answer{As I write this, we are working on a new keyboard shortcut system that would accommodate this.}
		      \item A gradient may have been better on the nodes.
		            The single color makes it harder to distinguish nodes whose \gls{nom} is similar. \agree \fxnote{Do we already support using a gradient? I can't remember.}
		      \item A less three-dimensional view may have been useful to navigate this city more easily.
		            \answer{This may be true here, since we have not used all three dimensions for metrics, but at its core, \SEE{} is a 3D \gls{city} visualization.}
	      \end{itemize}
	\item \textbf{Bug reports}:
	      \begin{itemize}
		      \item There were some smaller bugs that only became apparent after longer usage.
		      \item The \gls{window} could not be opened for one of the files in task $C$.
		      \item Using "show code" made \SEE{} freeze.
		            \answer{The above two problems are likely related, and this happened to me once too, but it also seems to occur non-deterministically, making it hard to debug.}
		      \item \SEE{} had to be restarted at one point because a node went missing.
		            \answer{The most likely explanation here is that the node was accidentally moved.
			            A "reset" button to completely undo any changes to a city's layout might be a good idea.}
		      \item Under Linux, the search menu is flickering, making it much harder to use.
		            \answer{I cannot replicate this, even though I am a Linux user---perhaps there are more specific sets of circumstances under which this bug occurs.}
		      \item Clicks in the tree view are sometimes transferred to the \gls{city} behind it.
		            \answer{We are aware of this problem and tracking it in issue \href{https://github.com/uni-bremen-agst/SEE/issues/702}{\proptt{\#702}}.}
	      \end{itemize}
	\item \textbf{Miscellaneous comments and criticism}:
	      \begin{itemize}
		      \item Edges drawn between clusters of nodes that are close to one another are hard to visually distinguish. $\bm{[2\times]}$
		            \answer{This is indeed a problem for denser clusters of nodes, but it is not immediately clear how to reliably solve this.}
		      \item A first-person camera combined with mouse controls is a very unfamiliar combination.
		      \item Quickly estimating which node has the highest \gls{nom} works well, but it is harder to gain confidence over numeric exactness.
		      \item It is cumbersome to check the \gls{nom} using the properties window.
		      \item \SEE{} is getting very visually appealing, and the transitive edge animations remind me of stones skipping across water, which is very cool.
	      \end{itemize}
\end{itemize}

\paragraph{\gls{vscode}}
\begin{itemize}
	\item It was great to use. $\bm{[2\times]}$
	\item An extension in \gls{vscode} with which metrics can be viewed directly in the \gls{ide} would have been helpful. $\bm{[2\times]}$
	      \answer{A related work is the bachelor's thesis by \textcite{herrmann2024}, which explores how visualizations of such metrics can be integrated into \gls{vscode} via an extension.}
	\item The feature set is huge.
	\item I was unsure if we were allowed to use the table for task $A$, which is why I slightly hesitated at first.
	\item The task seemed to only be solvable using the provided table.
	      \answer{This was intentional---the table was added to make the comparison to \SEE{} fair.}
	\item I would have rather used the command-line on Linux to solve tasks more quickly.
	      \answer{I agree that this would have been faster for an experienced developer, but the aim of the study was to compare \emph{\glspl{ide}} with \glspl{city}.}
	\item The symbols in \gls{vscode} were too small to reliably hit with the mouse.
	\item I prefer Emacs and Vim over \gls{vscode}. \agree
\end{itemize}

\paragraph{General Comments}
\begin{itemize}
	\item I found the question about the structure of the unit tests misleading.
	      \answer{Unfortunately, there were no further details in this comment, so I am not sure which part was misleading.
		      I have tried to give a detailed description of each type of unit test organization, but perhaps I should have added another tutorial question like I did for the \glspl{base}.}
	\item Telemetry functions in \gls{vscode} were active---this should never be the case in a study.
	      \answer{I fully agree and apologize for this oversight.}
	\item Without the table, solving the tasks would have been very difficult in \gls{vscode}.
	\item The study was well done.
\end{itemize}

\section{Threats to Validity}\label{sec:threats}
Before finishing this chapter, we want to take a look at some possible ways that the results from our study may be incorrect or misleading in some manner.
We group these potential problems into two categories:
\emph{Internal} threats to validity, which are about whether our study really measures the causal relationship between the independent and dependent variables, and \emph{external} threats to validity, which are about whether our results are generalizable.
We use the relevant threats listed by \textcite{campbell1963} as a basis here.

\subsection{Internal Validity}
We are controlling for \emph{selection} effects that would otherwise become an issue by randomly assigning participants to groups $\Psi$ and $\Omega$, both of which answer both task versions with opposite tools (see \cref{fig:taskflow}).
This way, there should be no systematic differences (such as \emph{History}, \emph{Experimental Mortality}) between the two groups\footnote{
	Seemingly by coincidence, there still were some significant differences between $\Psi$ and $\Omega$, but as \cref{subsec:experience} revealed, this should not have significantly influenced any of the dependent variables.
} that would bias the comparison between \gls{vscode} and \SEE{}.

By keeping the study relatively short, the threat of \emph{maturation} should also be adequately addressed.
There were some outlier participants that needed long enough for maturation effects like tiredness to become a concern, but as discussed in \cref{subsec:demographics}, they were almost certainly related to breaks rather than an actually long-winded participation time.
Additionally, the correctness results of the final JabRef tasks are proportionally very similar to the first SpotBugs tasks, which also suggests that participants did not get noticeably more tired as the study went on.

There may be some other interfering factors that caused type I or type II errors.
For example, as several participants noted, a copy-paste feature in \SEE{} (as it exists in \gls{vscode}) would have been helpful---while I do not personally think it would have mattered enough to cause any change in the results, it is possible that copy-pasting might have increased \SEE{}'s usability or decreased the time spent on tasks enough to cause a significant difference.
Another factor we may need to be aware of is that some participants know me personally.
Those participants could have (intentionally or unintentionally) tried to achieve a favorable result for me, such as \SEE{} having a higher usability rating than \gls{vscode}.
However, given that all significant differences point towards \gls{vscode} as the better tool, I am only left with the disturbing possibility that participants who know me personally tried to achieve a worse result for me, which is hopefully unlikely.

\subsection{External Validity}
While we tried to make this study as realistic as we could (\eg, by following the checklist by \textcite{wettel2011}), there are still several reasons why it might not have been completely representative of real-world scenarios.
For example, one concern is that our set of participants contains only one woman, and that a majority of participants are students who have helped develop \SEE{} (see \cref{subsec:demographics}), which is not necessarily representative.

Another potential problem is that the tasks or the setup could have been too unusual to be meaningfully realistic.
Two of the three tasks have been based on existing literature, and all seem reasonably typical to me in the context of trying to understand large software projects:
Identifying the biggest components in the codebase is a good starting point for finding \glspl{smell};
when adding new tests to a project, it is a good idea to first identifying the convention with which existing tests are organized;
and when trying to understand a certain class, it is often necessary to navigate up its inheritance hierarchy to investigate parts specified in superordinate classes.
However, in retrospect, some of the tasks (specifically $A$ and $C$) may have been too easy, given that almost no participants made any mistake, as seen in \cref{fig:correctness}.
This makes analysis of this aspect a bit harder insofar that we may miss relevant answers to our research question \textsf{RQ2} here (\eg, maybe there \emph{are} significant differences between \gls{lsp}-enabled \glspl{city} and \glspl{ide}, and our tasks were just too easy to catch them), but it should not be a big problem for the study as a whole, because time and usability were varied enough to cause meaningful results.

As for the setup, it consists of the subject systems (\SEE{} and \gls{vscode}) and the object systems (JabRef and SpotBugs).
JabRef and SpotBugs should be reasonably representative (see \cref{sec:design}) but the combination of \gls{vscode} together with external tables might be somewhat unusual.
It is probably more common to encounter a setup where such information is integrated into the \gls{ide}, for example, in the form of a \gls{smell} tool that tells the developer when components exceed certain metrics.
Still, this should not be too big a problem, as on the one hand, the same setup was used in Wettel's study, and on the other hand, setups like this do exist in the real world (\eg, the Axivion Dashboard, used in a similar comparative study~\cite[section~4.1]{galperin2021}, is such a tabular external tool).
However, even though we tried to reduce it (as discussed in \cref{sec:design}), our results might be biased due to the \gls{hawthorne} or related effects.
For example, I was not physically present for the tasks, but just knowing that they were being timed could have caused participants to perform worse than they would have without any perceived time pressure~\cite[\eg,][]{sussman2022a}.

\section{Interim Conclusion}
In this chapter, we evaluated our second research question \textsf{RQ2} by conducting a user study.
The study consisted of six program understanding tasks and compared the \gls{lsp}-integrated version of \SEE{} from \cref{ch:implementation} to the \gls{lsp}-enabled \gls{ide} \gls{vscode} together with tables listing code metrics.
Using the data of \participants participants, it turned out that some tasks took less perceived effort and were faster to solve when using \gls{vscode} instead of \SEE{}, with no other significant results.
Additionally, participants found \gls{vscode} significantly more usable than \SEE{}.
\Cref{tab:results} summarizes these results.

\begin{table*}[htbp]
	\caption{Significant differences between the variables, all in favor of \gls{vscode}.}\label{tab:results}
	\centering
	\begin{tabular}{@{}lcccccc@{}}
		\toprule
		\textbf{Variable}            & $\bm{A_1}$                              & $\bm{B_1}$ & $ \bm{C_1}$        & $\bm{A_2}$          & $\bm{B_2}$ & $\bm{C_2}$         \\\midrule
		\emph{Correctness}           & ---                                     & ---        & ---                & ---                 & ---        & ---                \\
		\emph{Time}                  & ---                                     & ---        & $p \approx 0.0015$ & ---                 & ---        & $p \approx 0.0247$ \\
		\emph{\gls{asq}: Complexity} & ---                                     & ---        & ---                & ---                 & ---        & ---                \\
		\emph{\gls{asq}: Effort}     & ---                                     & ---        & $p \approx 0.0142$ & $p \approx 0.00531$ & ---        & ---                \\
		\emph{\gls{sus}}             & \multicolumn{6}{c}{$p \approx 0.02116$}                                                                                           \\
		\bottomrule
	\end{tabular}
\end{table*}

Based on this data, we can answer \textsf{RQ2} as follows:
\Glspl{city} are a suitable means to present \gls{lsp} information, but developers work faster and report both lower perceived effort and higher usability ratings when using traditional \glspl{ide}, at least in the case of \SEE{} versus \gls{vscode}.
It is unclear what the exact cause of this difference is.
The \gls{sus} score of \SEE{} is very close to average \gls{sus} scores~\cite{sauro2013}, while \gls{vscode} reaches a very high score, so one possible reason is that \gls{vscode} is a much more polished and "tried-and-tested" product than \SEE{}, which made it easier to use.
Another possible cause is that software developers have much more day-to-day experience with traditional \glspl{ide} than with approaches like \SEE{}, making \gls{vscode} more intuitive and thus quicker and easier to use.
There are other possible reasons, such as our tasks possibly favoring \gls{vscode}'s interface:
For example, task $C$ is extremely easy and quick to do in \gls{vscode}:
After having found the initial file the task asks for, the participant merely needs to hold down \keystroke{Ctrl} and repeatedly click the name of the parent class, which is always right near the mouse cursor.
In \SEE{}, the participant instead has to visually follow the edges into what may be a pretty dense cluster of nodes, zoom in, and move the city around until the target of the edge is identified.

Looking at the existing research, we cannot replicate the results of \textcite{wettel2011,romano2019}, even though these use very similar tasks.
Both studies have as a result that \glspl{city} perform significantly better than \glspl{ide} under the factors of correctness and time, while we have the opposite result for time and no significant difference for correctness (though this latter part may have been because our tasks were too easy).
While \citeauthor{wettel2011}'s study did not measure usability, \citeauthor{romano2019}'s did, and found no difference when comparing the two tools, which is also different from our result where the \gls{ide} does better.
These differences could come from the fact that more tasks were used (twelve for \citeauthor{wettel2011} and ten for \citeauthor{romano2019}), making their experiments more representative, but it could also have been due to the choice of Eclipse as the \gls{ide}, which in one study by \textcite{morales2019} received an average \gls{sus} of $60.9$, lower than our average \SEE{} \gls{sus} score of $69.5$.

We can also make a comparison with the study for my bachelor's thesis, whose tasks $A$ and $B$ are very similar to our task $A$~\cite{galperin2022}.
There, I compared \SEE{} against the Axivion Dashboard, a web-based tabular \gls{smell} explorer, with the result being that using the Dashboard leads to higher correctness, but using \SEE{} leads to higher speed and a better \gls{asq} effort rating.
While this also goes against our results, we can at least replicate the difference between the \gls{sus}, as the Dashboard (analogously to \gls{vscode}) received a significantly higher score than \SEE{}.

In summary, our results here go against most of the existing literature covered in \cref{subsec:research}, especially when looking at \cref{tab:compresults}.
As said before, this may be due to the choice of \gls{ide} (the most-used \gls{ide} by other studies has been Eclipse, while we used \gls{vscode}), choice of \gls{city} implementation, or choice of tasks.
Further investigation into the exact causes here---perhaps by rigorously comparing various \glspl{ide}, \gls{city} tools, tasks, and so on, against each other in further user studies---could be a good avenue for future research.
