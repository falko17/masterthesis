\documentclass[../thesis]{subfiles}
\graphicspath{{\subfix{../figures/}}}

\begin{document}
\chapter{Implementation}\label{ch:implementation}

\lettrine[lines=3]{\textcolor{Maroon}{R}}{elying} on the foundations of \SEE{} and the \glsentrylong{lsp} established in the previous chapter, we can now turn to the core part of this thesis:
The integration of \gls{lsp} into \SEE{}, with a special focus on how to build \glspl{city} using \gls{lsp}'s \glspl{capability}.
We will start by briefly going over some preliminary changes to both \SEE{} and the \gls{lsp} specification.
Then, we will spend the majority of this chapter specifying and explaining the algorithm which "converts" \gls{lsp} information into \glspl{city}, before looking into how additional \glspl{capability} can be integrated into \SEE{}'s \glspl{city} and \glspl{window} specifically.
Finally, we will conduct a brief technical evaluation, with a more thorough user study following in the next chapter.

Before continuing with this chapter, I also highly recommend the reader to watch the six-minute showcase video at \url{https://www.youtube.com/watch?v=yAzyv2_q2ng}.
It goes over all important user-facing features and does a better job of presenting these than can be done in text alone.

\section{Preliminary Changes}
As promised in the preceding paragraph, we will first quickly list some preparations.

\subsection{Specification Cleanup}
While familiarizing myself with the \gls{lsp} specification, I noticed and fixed a few small issues along the way.
Most of these were of a formal nature (\eg, spelling, grammar, formatting, consistent usage of terms), some were fixing incorrect TypeScript syntax in the definition of \gls{lsp}'s data models.
The rest of the changes were related to the so-called snippet grammar.

In the context of \gls{lsp}, snippets are in essence string templates that are inserted on certain completions (see \cref{subsec:unplanned}), with some designed parts being filled in by the programmer on insertion.
There are also parts that can be filled in by certain values (\eg, the file name), which can themselves be transformed using regular expressions.\footnote{
	I am skipping over some additional features and details here because this is not that relevant a \gls{capability} for us---to get the full picture, see \web{https://microsoft.github.io/language-server-protocol/specifications/lsp/3.18/specification/\#snippet\_syntax}{2024-10-10}.
}
The complexity of the combinations of all these features increase the possibility of misunderstandings, which is why the snippet's grammar has been formally specified in \gls{ebnf}.
However, as it was written down in the specification, the grammar had a few problems that I have fixed.
Three notable examples are:
\begin{itemize}
	\item Some alternatives were incorrectly grouped, contradicting the explanatory text above them.
	      Also, the rules on how and when control characters had to be escaped were inconsistent with the surrounding text.\footnote{
		      This has lead to confusion in some projects making use of snippets.
		      See, for example, \web{https://github.com/neovim/neovim/issues/30495}{2024-10-10}.
	      }
	\item The grammar contained some string transformations that were unexplained in the text.
	      Since the \gls{lsp} specification is based on \gls{vscode}, I added explanations to the text based on what these transformations did in \gls{vscode}'s source code.
	\item Finally, there were ambiguities present in the grammar that led to \textsf{FIRST}/\textsf{FOLLOW} conflicts.
	      I have rewritten the grammar to eliminate these, and it should now be $LL(1)$-parseable~\cite[222--224]{aho2007}.

\end{itemize}


I have submitted these fixes as a pull request\footnote{\web{https://github.com/microsoft/language-server-protocol/pull/1886}{2024-10-10}}.
After addressing the resulting code review, it has been merged, and the changes will be incorporated in the upcoming 3.18 release of the specification.

\subsection{Preparing SEE}
There was not much I had to do in terms of getting \SEE{} ready, so this section will be very short:
\begin{itemize}
	\item I have integrated the OmniSharp \gls{lsp} C\# library\footnote{
		      Available at \web{https://github.com/OmniSharp/csharp-language-server-protocol}{2024-10-11}
	      } into \SEE{}, which we will leverage in the subsequent sections so that we can use \gls{lsp} without needing to worry about \gls{jrpc} encoding, data models, and so on.
	\item \Glspl{window} have previously been made editable by \textcite{moritz} in his bachelor thesis, also enabling collaborative editing over the internet.
	      I unfortunately had to remove these changes because they did not work anymore in the current version of \SEE{}, and additionally caused a lot of complexity overhead in the \gls{window} implementation that would have made the \gls{lsp} integration much harder to accomplish.
	\item Finally, the attribute space $\mathcal{A}$ in \SEE{} did not allow for \glspl{range} of the form \gls{lsp} needs, so I had to replace the existing attributes (which track the line and column, but not a full range) with a proper set of \gls{range} attributes.
	      In \cref{subsec:graph}, we have introduced this as a single \tt{Source.Range} attribute, but in reality, there are four \gls{range} attributes---one per member of the decomposed form.
	      We will ignore this reality for the rest of this thesis and act like the \gls{range} is a single attribute, that is, for all project graphs with nodes $V$ and attributes $a$, it holds that $\{a(v, \tt{Source.Range}) \mid v \in V \land (v, \tt{Source.Range}) \in \mathrm{dom}(a) \} \subseteq \mathcal{R}$.
\end{itemize}

All of these changes have been made across two pull requests to \SEE{}.\footnote{
	\url{https://github.com/uni-bremen-agst/SEE/pull/687} and \web{https://github.com/uni-bremen-agst/SEE/pull/715}{2024-10-11}.
}

\section{Generating Code Cities using LSP}\label{sec:generate}
In this section, we will examine the centerpiece of this thesis:
The algorithm with which \glspl{city} can be generated using the \glsentrylong{lsp}.
While going over how the algorithm works, we will take a quick look at \glspl{intervaltree} and how they relate to the algorithm, before finally taking a look at what the import process looks like in practice in \SEE{}.

\subsection{Algorithm}

We will take a look at the algorithm in a generalized and programming language independent form here.
In this form, the algorithm takes as input a set of source code documents, as well as a family of \gls{lsp} functions belonging to a specific instantiation of a \gls{ls}.
These functions will be used to analyze the documents and extract the required information from them.
The output of the algorithm, then, is a graph representing the given software project.

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{overview_algorithm}
	\end{center}
	\caption{A high-level overview of the basic steps of the algorithm.}\label{fig:alg_overview}
\end{figure}
\fxnote{Replace diagram sketch with TikZ picture.}

\paragraph{Overview}
Before diving into the specifics of \emph{how} the algorithm works, it may help to take a look at the diagram in \cref{fig:alg_overview}, which gives us a high-level overview of \emph{what} it does.
To summarize, the steps can be broken down into three major parts:
\begin{enumerate}[label=\bfseries\Roman*]
	\item \textbf{Node synthesis:} Here, we create the graph's nodes and combine them together into a hierarchy.
	      \begin{enumerate}[label=\arabic*.]
		      \item We recreate the parts of the filesystem hierarchy that are relevant to the given documents (\ie, directories the documents are contained in and their relation to each other).
		      \item For each code symbol within that document, a node will be created as a child to the document.
		            Any symbols contained within that symbol are recursively added in the same manner as a child to their parent nodes.
		      \item Finally, we will pull diagnostics for the document\footnote{
			            In the actual algorithm, we cannot rely on pulling diagnostics alone, since only few \glspl{ls} support this.
			            Instead, we will collect pushed diagnostics in the background and handle them all at once at the very end.
		            } and attach their counts to the nodes they correspond to.
	      \end{enumerate}
	\item \textbf{Edge synthesis:} Here, we connect the nodes by creating edges between them.
	      To do this, we go over each node, using \gls{lsp} functions to check for definition locations, references, and so on, and then determine which of our existing nodes best corresponds to that location.
	      This turns out to be the most difficult and complex part of the algorithm to implement efficiently, as we will later see.
	\item \textbf{Aggregation:} Finally, we want to aggregate \gls{loc} and diagnostic count metrics upwards in the hierarchy.
	      This way, we can, for example, see how many diagnostics are contained as a whole in a class, or even a directory.
\end{enumerate}

\paragraph{Specification}
Now that we know what it is the algorithm does, we can take a look at its detailed specification.
The specification is given in \cref{alg:generate} and follows a few special formatting rules that I will briefly list here:
\begin{itemize}
	\item Text in \textsc{Small Caps} refers to functions.
	      Those starting with \textsc{Lsp} specifically refer to functions provisioned by the \gls{ls}.
	\item Sentences in \textit{\textcolor{gray}{gray italics}} are comments.
	\item \textbf{Bold} text represents keywords.
	\item A normal font represents strings (\ie, text that represents itself).
	\item Finally, parts in a \texttt{typewriter font} have two purposes:
	      They represent attribute keys ($\in \mathcal{A}_K$) as well as properties of \gls{lsp}-returned objects, the latter of which are prefixed by a dot.
\end{itemize}

\Cpageref{alg:generate} contains the main algorithm.
We can map \cref{fig:alg_overview} onto it as follows:
\Crefrange{alg:generate:begin}{alg:generate:end1} contain part I (node synthesis),
\crefrange{alg:generate:end1}{alg:generate:end2} contain part II (edge synthesis),
and finally, \crefrange{alg:generate:end2}{alg:generate:end3} contain part III (aggregation) as well as handling of pushed diagnostics.

The following \cpagerefrange{alg:generate:funcstart}{alg:generate:funcend} contain the functions referenced in the main algorithm.
Here, we represent the "types" of each parameter by specifying the function domain, that is, by noting the sets each parameter must be in.
Most of these sets are already defined in \cref{ch:concepts} or the algorithm itself, but two exceptions to this are the set of \gls{lsp} code symbols~$\mathcal{S}$ and the set of \gls{lsp} diagnostics~$\mathcal{D}$ (not to be confused with the set of input documents~$D$).

\input{algorithm}

\paragraph{Simplifications}
As mentioned before, \cref{alg:generate} is a generalized version of the actual C\# algorithm that was implemented into \SEE{}.
Hence, a few simplifications\footnote{
	Apart from the obvious simplifications that occur naturally due to the difference between declarative mathematical notation and imperative programming syntax.
} were made to not make this section even more technical and longer than it already is.
Some noteworthy omissions are:
\begin{itemize}
	\item \textbf{Details on adding nodes,} such as the definition of the \textsc{NewNode} function, or the unique IDs assigned to each node.
	\item \textbf{The configuration of the algorithm.} We present it as only having two input parameters, but in reality, there are many additional explicit and implicit parameters (\eg, importing only certain types of nodes).
	      We will take a look at some of these configuration parameters that are relevant for the user in \cref{subsec:alg_editor}.
	      \begin{itemize}
		      \item Actually, even the two input parameters that we did include are simplifications.
		            In truth, the user selects a directory (instead of a set of documents), with the option to exclude some subdirectories, and we then automatically include every file with an extension that is relevant to the selected \gls{ls}.
	      \end{itemize}
	\item \textbf{Progress reporting.}
	      A progress bar noting the approximate progress (in percent) appears in both the \gls{editor}'s \gls{ui} as well as in-game while the \gls{city} is constructed, so the user has an idea of how long the conversion is going to take.
	\item \textbf{Asynchronicity.}
	      Specifically, this refers to the way the algorithm is executed in Unity.
	      If we were to implement it as a normal synchronous function, the \gls{ui} would become irresponsive to input and freeze until the whole algorithm is done.
	      Instead, we make use of C\#'s task-based \texttt{async} capabilities~\cite{wagner2023} in combination with the \texttt{UniTask}\footnote{
		      \web{https://github.com/Cysharp/UniTask}{2024-10-25}
	      } framework:
	      We yield control to the Unity event loop when progress is suspended (\eg{}, while we wait for an answer from the \gls{ls}), allowing frames to be rendered while the algorithm is running in the background.
	      This also allows us to implement cancellation support, making it possible for the user to cancel the algorithm at any time\footnote{
		      Internally, we do this by checking every so often if a so-called \emph{cancellation token} has been revoked by the user. If it has, we halt execution.
	      }.
	      \fxnote{Convert all software mentions to biblatex @software type.}
\end{itemize}

The full C\# implementation in \SEE{} is available at \web{https://github.com/uni-bremen-agst/SEE/blob/c4e3de908a022d65723bf82d3b350dade8b5f01a/Assets/SEE/DataModel/DG/IO/LSPImporter.cs}{2024-10-25}.

\paragraph{Performance Considerations}\label{subsec:performance}
When we analyze this algorithm in terms of complexity, we can quickly see that the most relevant portions are in matching locations to nodes, that is, \textsc{FindNodesByLocation}\footnote{
	At least, this is the case when we assume the runtime complexity of externally supplied \textsc{Lsp} functions is constant.
	This is an oversimplification, but the claim that this function is the most expensive part of the algorithm holds up to analyses of real-world test runs of the C\# algorithm.
}.
This is only meant to give a quick motivation on why we need the optimization described in \cref{subsec:kd}---a full complexity analysis of the algorithm is outside the scope of this thesis.
Part I as a whole (ignoring diagnostics, where \textsc{FindNodesByLocation} is called) can be considered to fall in $\Theta(|V|)$, since there is a constant amount of work per added node.
Part III (again ignoring diagnostics), as written, yields a worst-case runtime in $\mathcal{O}(|V|^2 \cdot |E|)$, because we potentially need to search through all edges for each node to identify child nodes, and this happens once per node while aggregating metrics upwards.
However, in the actual implementation, child nodes are saved alongside their parent and can be accessed in $\mathcal{O}(1)$, so this reduces to a runtime of $\Theta(|V|)$.

Part II is where things get interesting:
We are calling \textsc{ConnectNodeVia} a few times for each node (ignoring the handling of the type/call hierarchy, where very similar things happen), so let us look at what happens in here.
\textsc{ConnectNodeVia} first retrieves all target locations from the given \gls{lsp} function, and then calls \textsc{FindNodesByLocation} for each of those locations to identify the node in our graph to which the connecting edge should be drawn.
This effectively means \textsc{ConnectNodeVia} is called once per added (non-\tt{partOf}) edge.
In this function, each node's range is compared to the given location to check whether it is contained therein.
We then take the minimum over these nodes twice to determine the nodes with the most specific fit, so in total, the runtime of this function is in $\Theta(|V|)$.
This function is called once per added edge, and also once per diagnostics (because diagnostics also need to be associated to nodes), so part II's runtime can be said to be in $\Theta((|E| + n_d) \cdot |V|)$, where $n_d$ refers to the total number of diagnostics for the project.

Hence, the runtime for \cref{alg:generate} as a whole lies in $\Theta(|V| + |E| \cdot |V| + n_d \cdot |V| + |V|)$.
% TODO: Or \ll and \ggg
In practice for \gls{lsp}-built \glspl{city}, assuming the default configuration, $n_d < |V|$, but $|E| \gg |V|$.\fxnote{Put in examples or more concrete estimation of how much more edges there are than nodes.} % e.g., |E| > |V|^3.
Hence, part II with $\Theta(|E| \cdot |V|)$ easily dwarfs the rest of the algorithm's runtime due to the high cost of \textsc{FindNodesByLocation}, which searches through every node for every added edge.
For this reason, it would be nice to optimize that function somehow.
\fxwarning{Do actual comparison between two ways of finding target nodes. Also mention example times from eval section at end.}

\subsection{Augmented Interval Trees}\label{subsec:kd}
To restate the problem outlined in the performance considerations \fxwarning*{Rewrite "the above" to something else, may not be above in printed version}{above:}
The locations returned by \gls{lsp} functions such as "show references" or "go to location" need to be matched to the nodes in our constructed project graph.
We cannot simply create a lookup table from locations to nodes, as the locations are not necessarily equal to the location of the nodes, even when they describe the same logical element.
Instead, we need to match the location to the node with the "tightest fitting range",
that is: from the nodes whose \gls{range} completely contains the given location, we pick the one whose \gls{range} is the smallest (to find the most specific fitting element).
The naive solution used in \cref{alg:generate}---simply going over all nodes each time to find the best fit---leads to an unacceptable runtime.

There are a few possible ways to solve this problem (which is in essence a variant of the stabbing problem) more efficiently, such as segment trees or range trees, but we will use augmented \glspl{intervaltree} with \glspl{kdtree} as a base, as this configuration best fits our circumstances—there is no need to update/re-balance the tree (so the high cost associated with that is fine), the membership query should not be in $\Omega(n)$, we need to represent two dimensions (which is possible with a 2d-tree), and so on.

A detailed explanation of augmented \glspl{intervaltree} can be found in \textcite[section~17.3]{cormen2022}, while \glspl{kdtree} are described in a paper by \textcite{bentley1975}.
In our case, we can create the tree by constructing a 2d-tree\footnote{
	Note that, in the actual implementation, the construction of the \gls{kdtree} (excluding its augmentation to an \gls{intervaltree}) is handled by the external \tt{Supercluster.KDTree} library (\web{https://github.com/ericreg/Supercluster.KDTree}{2024-10-31}).
} out of all elements (as explained in the previous sources), where the key is the starting position of the \gls{range}.
Afterwards, we save in each node the maximum line number and maximum character offset, respectively, for the subtree rooted by that node, thereby turning this \gls{kdtree} into an \gls{intervaltree}.

An updated \textsc{FindNodesByLocationEfficient} is given in \cref{alg:interval}, with these details:
\begin{itemize}
	\item An augmented \gls{intervaltree} is modeled here as a quintuple $T = (v, l, c, \lambda, \rho)$.
	      The set of all such trees is defined as $\mathcal{T}$, so $T \in \mathcal{T}$.
	      The first element $v \in V$ is the node in the project graph represented by the node in this tree.
	      The second element $l \in \mathbb{N}_0$ refers to the maximum line number across all nodes within this tree, whereas the third element $c \in \mathbb{N}_0$ analogously refers to the maximum character offset.
	      The fourth element $\lambda \in \mathcal{T}$ refers to the left subtree rooted by this node, while the fifth element $\rho \in \mathcal{T}$ conversely refers to the right subtree.
	      Taking a single element $x$ from the tuple $T$ is written as $x_T$.
	\item We construct such an augmented \gls{intervaltree} for each document (directly after part~I in \cref{alg:generate}) and save them all in a hash table $H$ (modeled as a function $H: D \rightarrow \mathcal{T}$), where each document maps to its \gls{intervaltree}.
	\item Checking whether a \gls{range} $r_1$ is contained in another \gls{range} $r_2$ is written as $r_1 \subseteq r_2$.
	\item We need a way to compare two \glspl{range} against each other to check which one is "more specific".
	      The difficulty here is that the character offsets are hard to compare to each other, since the lines can be of different lengths---handling different line lengths correctly would be both algorithmically more expensive and harder to implement, so we have given up transitivity:
	      We define a homogeneous relation $\lesssim$ on $\mathcal{R}$ that is anti-reflexive and asymmetric (but not necessarily transitive), where $r_1 \lesssim r_2$ implies that $r_1$ is more specific than $r_2$.
	      Similarly, $\simeq$ is a homogeneous relation on $\mathcal{R}$ that is reflexive and symmetric (but also not necessarily transitive), where $r_1 \simeq r_2$ if they are both "equally as specific".\footnote{
		      My actual implementation of the \texttt{CompareTo} function can be found here: \web{https://github.com/uni-bremen-agst/SEE/blob/c4e3de908a022d65723bf82d3b350dade8b5f01a/Assets/SEE/DataModel/DG/Range.cs}{2024-10-31}.
	      }
\end{itemize}

\begin{algorithm}
	\small
	\tikzexternaldisable

	\caption{Efficiently associating \gls{lsp}-returned \glspl{range} to existing elements using an already constructed augmented \gls{intervaltree}.}\label{alg:interval}
	\begin{algorithmic}[1]
		\Function{FindNodesByLocationEfficientEfficient}{$d \in D, r \in \mathcal{R}$}
		\State \Return \Call{QueryTree}{$H(d), r, \varnothing$}
		\EndFunction

		\Statex
		\Function{QueryTree}{$T \in \mathcal{T}, q \in \mathcal{R}, R \subseteq V$}
		\State $r \gets a(v_T, \tt{Source.Range})$
		\If{$b^q_l > l_T \lor (b^q_l = l_T \land b^q_c \geq c_T)$}
		\Comment{Range is to the right of all nodes in this subtree.}
		\State \Return $R$
		\EndIf
		\If{$q \subseteq r$}
		\Comment{Range is contained in this node, but we want only minimal fits.}
		\State $m \gets \{v \in R \mid r \lesssim a(v, \tt{Source.Range}) \}$
		\If{$|m| > 0$} \Comment{This range is smaller than other results.}
		\State $R \gets (R \setminus m) \cup \{v_T\}$
		\ElsIf{$\forall v \in R: a(v, \tt{Source.Range}) \simeq r$} \Comment{Other ranges are equally minimal.}
		\State $R \gets R \cup \{v_T\}$
		\EndIf
		\LComment{Otherwise, $r$ is not minimal, so we don't add the node.}
		\EndIf

		\State $R \gets \Call{QueryTree}{\lambda_T, q, R}$
		\If{$e^q_l \geq b^r_l \land (e^q_l \neq b^r_l \lor e^q_c > b^r_c))$} \Comment{Range could be contained in right subtree.}
		\State $R \gets \Call{QueryTree}{\rho_T, q, R}$
		\EndIf
		\State \Return $R$
		\EndFunction
	\end{algorithmic}
	\tikzexternalenable
\end{algorithm}
\fxwarning{So how much does it help in practice? Reference tech eval here}

\begin{codebox}[minted options={linenos,escapeinside=++,firstnumber=0}]{csharp}{lst:interval}{Example C\# source code with demarcated symbol ranges.}
+\textcolor{red}{|}+public class Example {
  +\textcolor{Emerald}{|}+const char someValue = 'A'+\textcolor{Emerald}{|}+;

  +\textcolor{Peach}{|}+public static long pow(+\textcolor{OliveGreen}{|}+int num+\textcolor{OliveGreen}{|}+) {
    +\textcolor{Brown}{|}+long result = num * num+\textcolor{Brown}{|}+;
    return result;
  }+\textcolor{Peach}{|}+
}+\textcolor{red}{|}+
\end{codebox}

As a concrete example on how this works, take a look at the example code in \cref{lst:interval}.
Here, we have the following elements:
\begin{itemize}
	\item The \tt{Example} class with range \textcolor{red}{$(0,0,7,1)$}.
	\item The \tt{someValue} field with range \textcolor{Emerald}{$(1,2,1,28)$}.
	\item The \tt{pow} method with range \textcolor{Peach}{$(3,2,6,3)$}.
	\item The \tt{num} parameter with range \textcolor{OliveGreen}{$(3,25,3,32)$}.
	\item The \tt{result} variable with range \textcolor{Brown}{$(4,4,4,27)$}.
\end{itemize}

Now, if we were to convert this into an augmented 2-d \gls{intervaltree}, it might look like \cref{fig:example_kd}.
Here, the key refers to the starting position of each element and the max value refers to the maximum line and maximum character offset in the subtree rooted by each node.
Let us say we want to find out what the range $(1,13,1,22)$ (comprising just the name of \tt{someValue}) belongs to.
We will start by checking the root node \tt{pow}:
\begin{enumerate}
	\item $b^q_l < \textcolor{Peach}{l_{\tt{pow}}}$ because $1 < \textcolor{red}{7}$, so the range is not to the right of all nodes.
	\item It is not contained by \textcolor{Peach}{\texttt{pow}}'s range.
	\item We query the left subtree $\textcolor{Peach}{\lambda_{\tt{pow}}} = \textcolor{Emerald}{\tt{someValue}}$:
	      \begin{enumerate}
		      \item $b^q_l < \textcolor{Emerald}{l_{\tt{someValue}}}$ because $1 < \textcolor{red}{7}$, so the range is not to the right of all nodes.
		      \item It is contained by \textcolor{Emerald}{\tt{someValue}}'s range, so now $R = \{\textcolor{Emerald}{v_{\tt{someValue}}}\}$.
		      \item We query the left subtree $\textcolor{Emerald}{\lambda_{\tt{someValue}}} = \textcolor{red}{\tt{Example}}$.
		            \begin{enumerate}
			            \item $b^q_l < \textcolor{red}{l_{\tt{Example}}}$ because $1 < \textcolor{red}{7}$, so the range is not to the right of all nodes.
			            \item It is contained by \textcolor{red}{\tt{Example}}'s range, but $\textcolor{red}{r_{\tt{Example}}} \gtrsim \textcolor{Emerald}{r_{\tt{someValue}}}$, so \textcolor{Emerald}{\tt{someValue}} is still the tightest fit and $R$ stays as it is.
			            \item There are no subtrees.
		            \end{enumerate}
		      \item There is no right subtree.
	      \end{enumerate}
	\item $e^q_l \ngeq \textcolor{Peach}{b^r_l}$ because $1 < \textcolor{Peach}{3}$, so there is no need to check the right subtree.
	\item Our final result is $R = \{\textcolor{Emerald}{v_{\tt{someValue}}}\}$, which is intuitively the right answer.
\end{enumerate}

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{example_kd}
	\end{center}
	\caption{An augmented \gls{intervaltree} using a \gls{kdtree}, representing the elements in \cref{lst:interval}.}\label{fig:example_kd}
\end{figure}
\fxwarning{Convert to TikZ diagram and use colors from listing!}

This new and improved \textsc{FindNodesByLocation} implementation in \cref{alg:interval} has a runtime that is in both $\Omega(1)$ and $\mathcal{O}(k + \log |V|)$, where $k$ is the number of \glspl{range} that a node is contained in---however, its worst-case runtime is still in $\mathcal{O}(|V|)$, because in the worst case, the queried range is contained in every element in the tree, meaning $k = |V|$.
Still, this case is almost impossible in real-world generated graphs.
In actuality, a given range is only going to be contained by very few elements compared to the number of total elements within a given document tree.
Taking into account that in almost all situations, $k \ll |V|$, and especially $k < \log |V|$, our average-case runtime reduces to an upper bound of $\mathcal{O}(\log |V|)$.
Hence, while the theoretical worst-case runtime complexity stays the same, the average-case runtime of \cref{alg:generate} reduces from $\Theta(|V| + n_d \cdot |V| + |E| \cdot |V|)$ to $\mathcal{O}(|V| + n_d \cdot \log |V| + |E| \cdot \log |V|)$.
Since it is easy to make mistakes in the implementation due to the inherent complexity of this part, unit tests have also been implemented to make sure both normal and edge cases\footnote{
	No pun intended.
} are handled correctly.

\subsection{Usage in Practice}\label{subsec:alg_editor}
Now, we will have a quick look at how to actually use the algorithm in \SEE{}.
As explained before in \cref{subsec:seeother}, the \gls{lsp} importer---referring to the component responsible for using \cref{alg:generate} to generate a \gls{city}---is implemented as a \gls{provider}.
The \gls{ui} of that \gls{provider} in the \gls{editor} is shown in \cref{fig:unity_lsp_provider}.

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{unity_lsp_provider}
	\end{center}
	% Beware of sentences like the below, where all words except "for" and "the" are glossary terms.
	\caption{\gls{editor} \gls{ui} for the \gls{lsp} \gls{provider}}\label{fig:unity_lsp_provider}
\end{figure}

In that figure, we can see a configuration for the \tt{dcaf-rs} project\footnote{
	This is one of the sample projects we use in \cref{sec:techeval}'s technical evaluation.
}, where the \gls{ls} is the Rust Analyzer.
At the top, we can see that the path to the source project has been set, and that the \emph{Rust Analyzer}\footnote{
	The menu is grouped by language when opening it, hence the \texttt{Rust/} in front in \cref{fig:unity_lsp_provider}.
} has been selected as a \gls{ls}.
Below that, there is a field for "Source Paths".
This refers to the directories that shall be scanned for relevant documents, whereas a document's relevance is determined by its file extension.
This is distinct from the "Project Path" as that is instead used by the \gls{ls} to, for example, scan for project configuration files that describe dependencies.
Conversely, "Excluded Source Paths" can be used for those paths within the configured source paths that should be ignored (\eg, generated files, tests).

The selectable \glspl{ls} are only those that I have explicitly tested and confirmed to work with the algorithm---many servers are unusable, for example, due to required \glspl{capability} missing (such as the document symbols one).
All in all, there are working\footnote{
	There may well be more, I could not test some of the available \glspl{ls} either due to setup problems, or (like in the case of Wolfram Mathematica) because I do not have a license for the language in question.
} \glspl{ls} for the programming languages
C,
C++,
C\#,
Dart,
Go,
Haskell,
Java,
JavaScript,
Kotlin,
Lua,
MATLAB,
PHP,
Python,
Ruby,
Rust,
TypeScript,
and Zig.
There are also functioning \gls{ls} configurations for the miscellaneous languages
JSON,
\LaTeX{},
Markdown,
and XML.
A \gls{city} of a markup language like \LaTeX{}, for example, would have nodes for each section, figure, and so on, with edges representing references between these elements.

Next down the list in \cref{fig:unity_lsp_provider}, we have the import settings, which can be used to further refine the \gls{lsp}-generated data that is used for the project graph.
Specifically, we can select what kinds of nodes and edges we want to import, and which diagnostics we want to include.
Additionally, for the edges, there is the option to exclude loops and edges (excluding \tt{partOf}) to a node's direct parent.
The purpose behind this option is that otherwise, there are going to be a lot of definition/declaration edges from elements to their immediate parents, which happens because the locations returned by these \gls{lsp} functions often extend slightly outside the node's actual locations.
For example, a quirk of many \glspl{ls} is that a returned location may begin at \tt{\textcolor{red}{i}nt value;}, while the actual node for this variable starts at \tt{int \textcolor{red}{v}alue;}---in that case, the returned location would instead resolve to the outer container, such as the function it is contained in.

Finally, there is an option to enable the \gls{lsp} functions for \glspl{window} that are detailed in \cref{sec:intowindow}, a setting to generate log files for the transferred \gls{jrpc} messages, and a slider to adjust the maximum time we should wait for a \gls{ls}'s response to a request.
With all of these options configured, the graph can be loaded and drawn (and optionally exported to a \gls{gxl} file), where a bar displays the approximate progress of the process.
At this point, we will once again refer back to the explanatory video\footnote{\url{https://www.youtube.com/watch?v=yAzyv2_q2ng}},
which goes over the implemented functionality in a bit more detail and may be easier to follow along than this textual description.

\section{Integrating LSP Functionality into Code Cities}\label{sec:intocity}
After having examined how \glspl{city} are generated through the use of \gls{lsp}, we are now going to take a quick look at how some \gls{lsp} \glspl{capability} are integrated into \SEE{}.
For this section, we are going to purely focus on the interaction with the city itself, saving \glspl{window} for the following \cref{sec:intowindow}.

\subsection{Hover information}
The first thing I implemented was the functionality that, when hovering above nodes, the \gls{lsp} hover information should be displayed.
We already had an implementation for a tooltip that shows arbitrary text when hovering above nodes in \SEE{}, but I had to change it in two ways to work for this implementation:
\begin{enumerate}
	\item It is now a \gls{singleton} (since there will only be at most one tooltip per screen), making it easier to use as a caller.
	\item The tooltip now disappears when the user moves their mouse, and re-appears when the mouse is kept in place for a certain amount of time.
\end{enumerate}

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{HoverInfo}
	\end{center}
	\caption{A hover info tooltip with Markdown text converted to TextMeshPro rich text tags.}\label{fig:hoverinfo}
\end{figure}


Displaying the hover info is then relatively straightforward, as \cref{alg:generate} already saved it in the nodes of the city, so we need not even make any actual \gls{lsp} requests.
However, there is one more feature here that would be nice to support:
Some \glspl{ls} return the hover info as Markdown-formatted text instead of just plain text.
While Markdown by itself is still readable, we can leverage the XML-like rich text tags in Unity's TextMeshPro package\footnote{
	\web{http://digitalnativestudios.com/textmeshpro/docs/rich-text/}{2024-12-15}
} to display the Markdown text (partially, at least) in its proper formatting.
For this, I used the Markdig\footnote{\web{https://github.com/xoofx/markdig}{2024-15-12}} parser and implemented a custom renderer to output the corresponding TextMeshPro tags.
An example for a "rich" hover info tooltip like this can be seen in \cref{fig:hoverinfo}.

\subsection{Context Menu Navigation}
While the various connections between nodes (\ie{}, references, definitions, etc.) can already visually be represented as edges in the scene, this is not always the most accessible option.
% TODO: Link to benchmark here about edge vs node count count
For example, in very large projects, the huge number of edges would make it very hard to discern individual connections, so edges are often excluded from the rendering.
Another problem with edges is that, as the evaluation will show (see \cref{subsec:comments}), it is sometimes hard to discern which node a certain edge points to.

\begin{minipage}[t]{.75\textwidth}
	\centering
	\includegraphics[width=0.97\textwidth]{TreeWindow}
	\captionof{figure}{The tree view for a \gls{city} in \SEE{}.}\label{fig:treeview}
\end{minipage}%
\begin{minipage}[t]{.25\textwidth}
	\captionsetup{format=plain}
	\centering
	\includegraphics[width=0.9\textwidth]{CityContextMenu}
	\captionof{figure}{Context menu options for a node in an \gls{lsp}-enabled \gls{city}.}\label{fig:contextcity}
\end{minipage}

For cases like that, users could open the tree view for the city, which is a hierarchical 2D representation of the project graph, which also shows the outgoing and incoming edges for each node (see \cref{fig:treeview}).
However, although it is useful, it is still cumbersome to look around in the city and to then have to open this tree view and navigate around in it to find out what a certain node is connected to.
The context menu seems like a fitting place to remedy this:
Right-clicking a node opens a menu that is shown in \cref{fig:contextcity} with several actions, such as opening the tree view for this node or opening its \gls{window}.
As part of the implementation here, the context menu will now also display \gls{lsp} navigation entries such as "Show outgoing calls," given that corresponding edges exists.
Clicking on this entry leads to one of two things happening:
\begin{itemize}
	\item If there is only one target, it will be immediately highlighted with a spear and glow to make it easily identifiable in the scene.\footnote{
		      Once again, I recommend watching \href{https://www.youtube.com/watch?v=yAzyv2_q2ng}{the showcase video} to see this effect in action.
	      }
	\item If there is more than one target, a modified tree view will open, containing only the targets of the edge.
	      The user can click on one of the results here to trigger the highlighting described above.
\end{itemize}

\subsection{Diagnostics as Erosion Icons}
Finally, we are displaying \gls{lsp}-sourced diagnostics as erosion icons above each node.
As described in \cref{sec:generate} and specifically \cpageref{alg:generate:end3,alg:generate:funcend} of \cref{alg:generate}, we retrieve these diagnostics either by using the pull diagnostics \gls{capability} if it is available, or we collect pushed diagnostics during the import process.
We then associate diagnostics to nodes using the \gls{intervaltree}-based function described in \cref{subsec:kd}.
Finally, if the user enabled this in the configuration, we aggregate diagnostics upwards so that collected diagnostics can also be seen on the module they are in, for example.

We are not going to go into the details of the rendering and display of the nodes, as this just re-uses the same mechanisms as the implementation from my bachelor's thesis~\cite[section~3.3]{galperin2021}.
There were only minimal changes, like the integration of new icons for the different \gls{lsp} diagnostic types, and a change that allows leaf erosion icons to be displayed on non-leaf nodes, since the \gls{lsp} diagnostics are not always present at the lowest level in the hierarchy.

\section{Integrating LSP Functionality into Code Windows}\label{sec:intowindow}
Now we will go over how the functionalities of \glspl{ls} have been integrated into \glspl{window} to make them more \gls{ide}-like.

\subsection{Syntax Highlighting}

% Reference table: This is where most LOCs came from.

% Semantic Tokens
% Diagnostics
% Hover
% Navigation
% Mention reported bug

\fxfatal{}

\section{Technical Evaluation}\label{sec:techeval}
Before ending this chapter, we want to briefly evaluate the implementation on a technical level.
While there are some unit tests for parts of the algorithm, taking real-world projects and trying to generate \glspl{city} out of them using our implementation is important to verify that it is working correctly too.
Apart from a quick qualitative glance at each generated city, we are also interested in an analysis of performance here---we made quite a few theoretical statements and analyses in \cref{sec:generate}, so we can also use this section to make sure the \gls{intervaltree}-based \cref{alg:interval} actually does work more efficiently than the original "brute-force" approach of \cref{alg:generate}.

We have run the city generation algorithm on the following projects:
\begin{itemize}
	\item \textbf{JabRef}: A bibliography manager written in Java.
	\item \textbf{SpotBugs}: A bug-detector using static analysis for Java code.
	\item \textbf{\proptt{dcaf-rs}}: A Rust project about authentication in the Internet of Things.
	\item \textbf{\proptt{aaoffline}}: A Rust downloader for a certain kind of online-hosted mystery game.
	\item \textbf{\LaTeX{} source of this master's thesis}\footnote{
		      I could not use the whole content of the thesis---for example, it would have been difficult to include the results of the technical evaluation while I was still in the process of collecting them.
	      }: Self-explanatory.
	\item \textbf{\LaTeX{} source of my bachelor's thesis}: Self-explanatory.
\end{itemize}

The source code for these projects is linked in \fxnote*{Link to appendix}{TODO}.
The algorithm was repeated three times for the first two projects and five times for the others\footnote{
	The difference stems from the fact that the generation for JabRef and SpotBugs took much longer.
}, to make sure that any single result was not an outlier.
For the generation, we enabled every edge type, node type, and diagnostic, except for JabRef and SpotBugs, where we only enabled some node types (namely File, Module, Namespace, Package, Class, and Interface) and only one edge type (Extend for JabRef and Reference for SpotBugs), otherwise the generation would have taken much too long.
\Cref{tab:benchmark} lists all projects along with their node count, edge count, \gls{loc}, and average generation time.

\begin{table*}[htbp]
	\caption{Relevant metadata for all evaluated projects, along with the average total generation time.}\label{tab:benchmark}
	\begin{tabular}{@{}llccccc@{}}
		\toprule
		\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Name}}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{\Gls{ls}}}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{k\gls{loc}}}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{\# Nodes}}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{\# Edges}}} & \multicolumn{2}{c}{\textbf{Average Time [h:m]}}                 \\
		                                                   &                                                        &                                                          &                                                        &                                                        & {Optimized}                                     & {Brute-force} \\
		\midrule
		\textit{JabRef}                                    & Eclipse JDT                                            & $179$                                                    & $5575$                                                 & $919$                                                  & $4$:$17$                                        & $4$:$29$      \\
		\textit{SpotBugs}                                  & Eclipse JDT                                            & $216$                                                    & $3813$                                                 & $16262$                                                & $9$:$22$                                        & $43$:$11$     \\
		\textit{\proptt{dcaf-rs}}                          & Rust Analyzer                                          & $16.5$                                                   & $1192$                                                 & $9940$                                                 & $4$:$27$                                        & $5$:$59$      \\
		\textit{\proptt{aaoffline}}                        & Rust Analyzer                                          & $3.3$                                                    & $515$                                                  & $1250$                                                 & $0$:$46$                                        & $0$:$56$      \\
		\textit{Master's thesis}                           & \proptt{texlab}                                        & $2.5$                                                    & $301$                                                  & $24048$                                                & $0$:$10$                                        & $0$:$36$      \\
		\textit{Bachelor's thesis}                         & \proptt{texlab}                                        & $2$                                                      & $376$                                                  & $46348$                                                & $0$:$13$                                        & $2$:$31$      \\ \bottomrule
	\end{tabular}
\end{table*}

The first thing that is worth mentioning here is that generations by different \glspl{ls} are not really comparable to one another.
For example, we can see that the generation run for this thesis took on average nine seconds---faster than any other project---even though there were more edges than in almost every other project.
This difference cannot be explained by the idea that edges may not play a big role in generation time after all, since a closer look at the data for JabRef and SpotBugs reveals a much longer generation time for SpotBugs, even though SpotBugs has less nodes (but a lot more edges) than JabRef.
Hence, the difference there has to come from the different \glspl{ls}.

\begin{figure}
	\tikzexternaldisable
	\begin{subfigure}[T]{0.5\textwidth}
		\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
						ylabel={Time in seconds},
						height=10cm,
						ybar stacked,
						name=bars,
						set layers,
						ymin=0, ymax=370,
						axis x line*=bottom,
						axis y line*=left,
						enlarge x limits={0.5},
						ymajorgrids,
						bar width=0.6cm,
						x tick label style={rotate=45, anchor=east, align=left, font=\scriptsize, yshift=-2},
						xtick=data,
						width=\textwidth,
						xticklabels={\proptt{aaoffline}-O, \proptt{aaoffline}-B, \proptt{dcaf-rs}-O, \proptt{dcaf-rs}-B},
						xtick={0,1,3,4},
					]

					\addplot+[fill] table [x=index,y=LSP Nodes,col sep=tab] {benchmark/rust.dat};
					\addplot+[fill] table [x=index,y=LSP Edges,col sep=tab] {benchmark/rust.dat};
					\addplot+[fill] table [x=index,y=LSP Diagnostics,col sep=tab] {benchmark/rust.dat};
					\addplot+[fill] table [x=index,y=LSP Aggregate,col sep=tab] {benchmark/rust.dat};
					\addplot+[fill] table [x=index,y=LSP Tree,col sep=tab] {benchmark/rust.dat};
					\addplot+[fill] table [x=index,y=LSP Miscellaneous,col sep=tab] {benchmark/rust.dat};
				\end{axis}
				\plotornaments{bars}
			\end{tikzpicture}
		\end{center}
	\end{subfigure}
	\begin{subfigure}[T]{0.5\textwidth}
		\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
						height=10cm,
						ybar stacked,
						name=bars,
						set layers,
						ymin=0, ymax=155,
						axis x line*=bottom,
						axis y line*=left,
						enlarge x limits={0.5},
						ymajorgrids,
						bar width=0.6cm,
						x tick label style={rotate=45, anchor=east, align=left, font=\scriptsize, yshift=-2},
						xtick=data,
						width=\textwidth,
						xticklabels={Bachelor-O, Bachelor-B, Master-O, Master-B},
						xtick={0,1,3,4},
						legend entries={Nodes, Edges, Diagnostics, Aggregation, Tree Creation, Miscellaneous},
						legend style={nodes={scale=0.7, transform shape}, at={(0.95,0.9)}}
					]

					\addplot+[fill] table [x=index,y=LSP Nodes,col sep=tab] {benchmark/tex.dat};
					\addplot+[fill] table [x=index,y=LSP Edges,col sep=tab] {benchmark/tex.dat};
					\addplot+[fill] table [x=index,y=LSP Diagnostics,col sep=tab] {benchmark/tex.dat};
					\addplot+[fill] table [x=index,y=LSP Aggregate,col sep=tab] {benchmark/tex.dat};
					\addplot+[fill] table [x=index,y=LSP Tree,col sep=tab] {benchmark/tex.dat};
					\addplot+[fill] table [x=index,y=LSP Miscellaneous,col sep=tab] {benchmark/tex.dat};
				\end{axis}
				\plotornaments{bars}
			\end{tikzpicture}
		\end{center}
	\end{subfigure}\\
	\begin{subfigure}[T]{0.5\textwidth}
		\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
						ylabel={Time in seconds},
						height=10cm,
						ybar stacked,
						name=bars,
						set layers,
						ymin=0, ymax=280,
						xmin=0, xmax=1,
						axis x line*=bottom,
						axis y line*=left,
						enlarge x limits={1},
						ymajorgrids,
						bar width=0.6cm,
						x tick label style={rotate=45, anchor=east, align=left, font=\scriptsize, yshift=-2},
						xtick=data,
						width=\textwidth,
						xticklabels={JabRef-O, JabRef-B},
						xtick={0,1},
					]

					\addplot+[fill] table [x=index,y=LSP Nodes,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Edges,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Diagnostics,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Aggregate,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Tree,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Miscellaneous,col sep=tab] {benchmark/java.dat};
				\end{axis}
				\plotornaments{bars}
			\end{tikzpicture}
		\end{center}
	\end{subfigure}
	\begin{subfigure}[T]{0.5\textwidth}
		\begin{center}
			\begin{tikzpicture}
				\begin{axis}[
						height=10cm,
						ybar stacked,
						name=bars,
						set layers,
						ymin=0, ymax=2700,
						axis x line*=bottom,
						axis y line*=left,
						xmin=3, xmax=4,
						enlarge x limits={1},
						ymajorgrids,
						bar width=0.6cm,
						x tick label style={rotate=45, anchor=east, align=left, font=\scriptsize, yshift=-2},
						xtick=data,
						width=\textwidth,
						xticklabels={SpotBugs-O, SpotBugs-B},
						xtick={3,4},
					]

					\addplot+[fill] table [x=index,y=LSP Nodes,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Edges,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Diagnostics,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Aggregate,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Tree,col sep=tab] {benchmark/java.dat};
					\addplot+[fill] table [x=index,y=LSP Miscellaneous,col sep=tab] {benchmark/java.dat};
				\end{axis}
				\plotornaments{bars}
			\end{tikzpicture}
		\end{center}
	\end{subfigure}
	\caption{Generation time for each project, broken down by parts of the algorithm.
		The suffix \emph{O} denotes the optimized (\gls{intervaltree}) version of the algorithm, while \emph{B} refers to the brute-force version.
	}\label{fig:techeval}
	\tikzexternalenable
\end{figure}

\fxwarning{Bar plot corners overlap with ornaments}

% Visualizations / Analyses:
% - Taking a look at the city itself, making sure it looks right.
% - What I want to show:
%   - Normal running time vs optimized running time.
%   - Running time of various parts of the algorithm (in percent?)
%   - Advantage of optimized over brute force compared to num edges!
% - Plot [] VS [Nodes/Edges]
% - Maybe Scatter Plot for time and edges?
% - Maybe Stacked Bar Chart for time components per system?

\fxfatal{}

\section{Interim Conclusion}\label{sec:implconclusion}
\fxfatal{}

% TODO: Mention potential for improvement: JabRef/SpotBugs with all edge/node types would have been way too long, but SEE would be ideal for very large projects.

% TODO: Mention PR for user study changes (maybe in city section actually?)

% TODO: Reference table

\begin{table*}[htbp]
	\newcommand{\githubpr}[2]{\href{https://github.com/#1/pull/#2}{\proptt{#1\##2}}}
	\newcommand{\diffsum}[2]{\textcolor{Green}{\ensuremath{#1}} & \textcolor{Red}{\ensuremath{#2}}}
	\caption{All submitted pull requests done as part of this thesis.}\label{tab:code}
	\begin{tabular}{@{}llrl@{}}
		\toprule
		\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Summary}}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Pull Request URI}}} & \multicolumn{2}{c}{\>\> $\mathbf{\Delta}$ \textbf{LOC}}                \\
		                                                      &                                                                & $\mathbf{+}$                                            & $\mathbf{-}$ \\
		\midrule
		Cleanup of \gls{lsp} specification                    & \githubpr{microsoft/language-server-protocol}{1886}            & \diffsum{475}{453}                                                     \\
		Preparing \SEE{} for \gls{lsp} integration            & \githubpr{uni-bremen-agst/SEE}{687}                            & \diffsum{282}{2773}                                                    \\
		Introducing \tt{Source.\Gls{range}}                   & \githubpr{uni-bremen-agst/SEE}{715}                            & \diffsum{392}{313}                                                     \\
		Generating \glspl{city} using \gls{lsp}               & \githubpr{uni-bremen-agst/SEE}{727}                            & \diffsum{3475}{180}                                                    \\
		\gls{lsp} functions in \glspl{city}                   & \githubpr{uni-bremen-agst/SEE}{747}                            & \diffsum{1139}{432}                                                    \\
		\gls{lsp} functions in \glspl{window}                 & \githubpr{uni-bremen-agst/SEE}{751}                            & \diffsum{4080}{2024}                                                   \\
		Preparing \SEE{} for user study                       & \githubpr{uni-bremen-agst/SEE}{772}                            & \diffsum{541}{150}                                                     \\
		\bottomrule
	\end{tabular}
	\caption*{\footnotesize Only C\# line changes have been counted in \SEE{} pull requests.\\
		GitHub pull requests are specified in the format \tt{namespace/repository\#PR\_number}.
	}

\end{table*}

