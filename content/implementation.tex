\documentclass[../thesis]{subfiles}
\graphicspath{{\subfix{../figures/}}}

\begin{document}
\chapter{Implementation}\label{ch:implementation}

\lettrine[lines=3]{\textcolor{Maroon}{R}}{elying} on the foundations of \SEE{} and the \glsentrylong{lsp} established in the previous chapter, we can now turn to the core part of this thesis:
The integration of \gls{lsp} into \SEE{}, with a special focus on how to build \glspl{city} using \gls{lsp}'s \glspl{capability}.
We will start by briefly going over some preliminary changes to both \SEE{} and the \gls{lsp} specification.
Then, we will spend the majority of this chapter specifying and explaining the algorithm which "converts" \gls{lsp} information into \glspl{city}, before looking into how additional \glspl{capability} can be integrated into \SEE{}'s \glspl{city} and \glspl{window} specifically.
Finally, we will conduct a brief technical evaluation, with a more thorough user study following in the next chapter.

\section{Preliminary Changes}
As promised in the preceding paragraph, we will first quickly list some preparations.

\subsection{Specification Cleanup}
While familiarizing myself with the \gls{lsp} specification, I noticed and fixed a few small issues along the way.
Most of these were of a formal nature (\eg, spelling, grammar, formatting, consistent usage of terms), some were fixing incorrect TypeScript syntax in the definition of \gls{lsp}'s data models.
The rest of the changes were related to the so-called snippet grammar.

In the context of \gls{lsp}, snippets are in essence string templates that are inserted on certain completions (see \cref{subsec:unplanned}), with some designed parts being filled in by the programmer on insertion.
There are also parts that can be filled in by certain values (\eg, the file name), which can themselves be transformed using regular expressions.\footnote{
	I am skipping over some additional features and details here because this is not that relevant a \gls{capability} for us---to get the full picture, see \web{https://microsoft.github.io/language-server-protocol/specifications/lsp/3.18/specification/\#snippet\_syntax}{2024-10-10}.
}
The complexity of the combinations of all these features increase the possibility of misunderstandings, which is why the snippet's grammar has been formally specified in \gls{ebnf}.
However, as it was written down in the specification, the grammar had a few problems that I have fixed.
Three notable examples are:
\begin{itemize}
	\item Some alternatives were incorrectly grouped, contradicting the explanatory text above them.
	      Also, the rules on how and when control characters had to be escaped were inconsistent with the surrounding text.\footnote{
		      This has lead to confusion in some projects making use of snippets.
		      See, for example, \web{https://github.com/neovim/neovim/issues/30495}{2024-10-10}.
	      }
	\item The grammar contained some string transformations that were unexplained in the text.
	      Since the \gls{lsp} specification is based on \gls{vscode}, I added explanations to the text based on what these transformations did in \gls{vscode}'s source code.
	\item Finally, there were ambiguities present in the grammar that led to \textsf{FIRST}/\textsf{FOLLOW} conflicts.
	      I have rewritten the grammar to eliminate these, and it should now be $LL(1)$-parseable~\cite[222--224]{aho2007}.

\end{itemize}


I have submitted these fixes as a pull request\footnote{\web{https://github.com/microsoft/language-server-protocol/pull/1886}{2024-10-10}}.
After addressing the resulting code review, it has been merged, and the changes will be incorporated in the upcoming 3.18 release of the specification.

\subsection{Preparing SEE}
There was not much I had to do in terms of getting \SEE{} ready, so this section will be very short:
\begin{itemize}
	\item I have integrated the OmniSharp \gls{lsp} C\# library\footnote{
		      Available at \web{https://github.com/OmniSharp/csharp-language-server-protocol}{2024-10-11}
	      } into \SEE{}, which we will leverage in the subsequent sections so that we can use \gls{lsp} without needing to worry about \gls{jrpc} encoding, data models, and so on.
	\item \Glspl{window} have previously been made editable by \textcite{moritz} in his bachelor thesis, also enabling collaborative editing over the internet.
	      I unfortunately had to remove these changes because they did not work anymore in the current version of \SEE{}, and additionally caused a lot of complexity overhead in the \gls{window} implementation that would have made the \gls{lsp} integration much harder to accomplish.
	\item Finally, the attribute space $\mathcal{A}$ in \SEE{} did not allow for \glspl{range} of the form \gls{lsp} needs, so I had to replace the existing attributes (which track the line and column, but not a full range) with a proper set of \gls{range} attributes.
	      In \cref{subsec:graph}, we have introduced this as a single \tt{Source.Range} attribute, but in reality, there are four \gls{range} attributes---one per member of the decomposed form.
	      We will ignore this reality for the rest of this thesis and act like the \gls{range} is a single attribute, that is, for all project graphs with nodes $V$ and attributes $a$, it holds that $\{a(v, \tt{Source.Range}) \mid v \in V \land (v, \tt{Source.Range}) \in \mathrm{dom}(a) \} \subseteq \mathcal{R}$.
\end{itemize}

All of these changes have been made across two pull requests to \SEE{}.\footnote{
	\url{https://github.com/uni-bremen-agst/SEE/pull/687} and \web{https://github.com/uni-bremen-agst/SEE/pull/715}{2024-10-11}.
}

\section{Generating Code Cities using LSP}\label{sec:generate}
In this section, we will examine the centerpiece of this thesis:
The algorithm with which \glspl{city} can be generated using the \glsentrylong{lsp}.
While going over how the algorithm works, we will take a quick look at \glspl{intervaltree} and how they relate to the algorithm, before finally taking a look at what the import process looks like in practice in \SEE{}.

\subsection{Algorithm}

We will take a look at the algorithm in a generalized and programming language independent form here.
In this form, the algorithm takes as input a set of source code documents, as well as a family of \gls{lsp} functions belonging to a specific instantiation of a \gls{ls}.
These functions will be used to analyze the documents and extract the required information from them.
The output of the algorithm, then, is a graph representing the given software project.

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{overview_algorithm}
	\end{center}
	\caption{A high-level overview of the basic steps of the algorithm.}\label{fig:alg_overview}
\end{figure}
\fxnote{Replace diagram sketch with TikZ picture.}

\paragraph{Overview}
Before diving into the specifics of \emph{how} the algorithm works, it may help to take a look at the diagram in \cref{fig:alg_overview}, which gives us a high-level overview of \emph{what} it does.
To summarize, the steps can be broken down into three major parts:
\begin{enumerate}[label=\bfseries\Roman*]
	\item \textbf{Node synthesis:} Here, we create the graph's nodes and combine them together into a hierarchy.
	      \begin{enumerate}[label=\arabic*.]
		      \item We recreate the parts of the filesystem hierarchy that are relevant to the given documents (\ie, directories the documents are contained in and their relation to each other).
		      \item For each code symbol within that document, a node will be created as a child to the document.
		            Any symbols contained within that symbol are recursively added in the same manner as a child to their parent nodes.
		      \item Finally, we will pull diagnostics for the document\footnote{
			            In the actual algorithm, we cannot rely on pulling diagnostics alone, since only few \glspl{ls} support this.
			            Instead, we will collect pushed diagnostics in the background and handle them all at once at the very end.
		            } and attach their counts to the nodes they correspond to.
	      \end{enumerate}
	\item \textbf{Edge synthesis:} Here, we connect the nodes by creating edges between them.
	      To do this, we go over each node, using \gls{lsp} functions to check for definition locations, references, and so on, and then determine which of our existing nodes best corresponds to that location.
	      This turns out to be the most difficult and complex part of the algorithm to implement efficiently, as we will later see.
	\item \textbf{Aggregation:} Finally, we want to aggregate \gls{loc} and diagnostic count metrics upwards in the hierarchy.
	      This way, we can, for example, see how many diagnostics are contained as a whole in a class, or even a directory.
\end{enumerate}

\paragraph{Specification}
Now that we know what it is the algorithm does, we can take a look at its detailed specification.
The specification is given in \cref{alg:generate} and follows a few special formatting rules that I will briefly list here:
\begin{itemize}
	\item Text in \textsc{Small Caps} refers to functions.
	      Those starting with \textsc{Lsp} specifically refer to functions provisioned by the \gls{ls}.
	\item Sentences in \textit{\textcolor{gray}{gray italics}} are comments.
	\item \textbf{Bold} text represents keywords.
	\item A normal font represents strings (\ie, text that represents itself).
	\item Finally, text in a \texttt{typewriter font} have two purposes:
	      They represent attribute keys ($\in \mathcal{A}_K$) as well as properties of \gls{lsp}-returned objects, the latter of which are prefixed by a dot.
\end{itemize}

\Cpageref{alg:generate} contains the main algorithm.
We can map \cref{fig:alg_overview} onto it as follows:
\Crefrange{alg:generate:begin}{alg:generate:end1} contain part I (node synthesis),
\crefrange{alg:generate:end1}{alg:generate:end2} contain part II (edge synthesis),
and finally, \crefrange{alg:generate:end2}{alg:generate:end3} contain part III (aggregation) as well as handling of pushed diagnostics.

The following \cpagerefrange{alg:generate:funcstart}{alg:generate:funcend} contain the functions referenced in the main algorithm.
Here, we represent the "types" of each parameter by specifying the function domain, that is, by noting the sets each parameter must be in.
Most of these sets are already defined in \cref{ch:concepts} or the algorithm itself, but two exceptions to this are the set of \gls{lsp} code symbols~$\mathcal{S}$ and the set of \gls{lsp} diagnostics~$\mathcal{D}$ (not to be confused with the set of input documents~$D$).

\input{algorithm}

\paragraph{Simplifications}
As mentioned before, \cref{alg:generate} is a generalized version of the actual C\# algorithm that was implemented into \SEE{}.
Hence, a few simplifications\footnote{
	Apart from the obvious simplifications that occur naturally due to the difference between declarative mathematical notation and imperative programming syntax.
} were made to not make this section even more technical and longer than it already is.
Some noteworthy omissions are:
\begin{itemize}
	\item Details on adding nodes, such as the definition of the \textsc{NewNode} function, or the unique IDs assigned to each node.
	\item The configuration of the algorithm. We present it as only having two input parameters, but in reality, there are many additional explicit and implicit parameters (\eg, importing only certain types of nodes).
	      We will take a look at some of these configuration parameters that are relevant for the user in \cref{subsec:alg_editor}.
	      \begin{itemize}
		      \item Actually, even the two input parameters that we did include are simplifications.
		            In truth, the user selects a directory (instead of a set of documents), with the option to exclude some subdirectories, and we then automatically include every file with an extension that is relevant to the selected \gls{ls}.
	      \end{itemize}
	\item Progress reporting.
	      A progress bar noting the approximate progress (in percent) appears in both the \gls{editor}'s \gls{ui} as well as in-game while the \gls{city} is constructed, so the user has an idea of how long the conversion is going to take.
	\item Asynchronicity.
	      Specifically, this refers to the way the algorithm is executed in Unity.
	      If we were to implement it as a normal synchronous function, the \gls{ui} would become irresponsive to input and freeze until the whole algorithm is done.
	      Instead, we make use of C\#'s task-based \texttt{async} capabilities~\cite{wagner2023} in combination with the \texttt{UniTask}\footnote{
		      \web{https://github.com/Cysharp/UniTask}{2024-10-25}
	      } framework:
	      We yield control to the Unity event loop when progress is suspended (\eg{}, while we wait for an answer from the \gls{ls}), allowing frames to be rendered while the algorithm is running in the background.
	      This also allows us to implement cancellation support, making it possible for the user to cancel the algorithm at any time\footnote{
		      Internally, we do this by checking every so often if a so-called \emph{cancellation token} has been revoked by the user. If it has, we halt execution.
	      }.
	      \fxnote{Convert all software mentions to biblatex @software type.}
\end{itemize}

The full C\# implementation in \SEE{} is available at \web{https://github.com/uni-bremen-agst/SEE/blob/c4e3de908a022d65723bf82d3b350dade8b5f01a/Assets/SEE/DataModel/DG/IO/LSPImporter.cs}{2024-10-25}.

\paragraph{Performance Considerations}
When we analyze this algorithm in terms of complexity, we can quickly see that the most relevant portions are in matching locations to nodes, that is, \textsc{FindNodesByLocation}\footnote{
	At least, this is the case when we assume the runtime complexity of externally supplied \textsc{Lsp} functions is constant.
	This is an oversimplification, but the claim that this function is the most expensive part of the algorithm holds up to analyses of real-world test runs of the C\# algorithm.
}.
This is only meant to give a quick motivation on why we need the optimization described in \cref{subsec:kd}---a full complexity analysis of the algorithm is outside the scope of this thesis.
Part I as a whole (ignoring diagnostics, where \textsc{FindNodesByLocation} is called) can be considered to fall in $\Theta(|V|)$, since there is a constant amount of work per added node.
Part III (again ignoring diagnostics), as written, yields a worst-case runtime in $\mathcal{O}(|V|^2 \cdot |E|)$, because we potentially need to search through all edges for each node to identify child nodes, and this happens once per node while aggregating metrics upwards.
However, in the actual implementation, child nodes are saved alongside their parent and can be accessed in $\mathcal{O}(1)$, so this reduces to a runtime of $\Theta(|V|)$.

Part II is where things get interesting:
We are calling \textsc{ConnectNodeVia} a few times for each node (ignoring the handling of the type/call hierarchy, where very similar things happen), so let us look at what happens in here.
\textsc{ConnectNodeVia} first retrieves all target locations from the given \gls{lsp} function, and then calls \textsc{FindNodesByLocation} for each of those locations to identify the node in our graph to which the connecting edge should be drawn.
This effectively means \textsc{ConnectNodeVia} is called once per added (non-\tt{partOf}) edge.
In this function, each node's range is compared to the given location to check whether it is contained therein.
We then take the minimum over these nodes twice to determine the nodes with the most specific fit, so in total, the runtime of this function is in $\Theta(|V|)$.
This function is called once per added edge, and also once per diagnostics (because diagnostics also need to be associated to nodes), so part II's runtime can be said to be in $\Theta((|E| + n_d) \cdot |V|)$, where $n_d$ refers to the total number of diagnostics for the project.

Hence, the runtime for \cref{alg:generate} as a whole lies in $\Theta(|V| + |E| \cdot |V| + n_d \cdot |V| + |V|)$.
% TODO: Or \ll and \ggg
In practice for \gls{lsp}-built \glspl{city}, assuming the default configuration, $n_d < |V|$, but $|E| \gg |V|$.\fxnote{Put in examples or more concrete estimation of how much more edges there are than nodes.} % e.g., |E| > |V|^3.
Hence, part II with $\Theta(|E| \cdot |V|)$ easily dwarfs the rest of the algorithm's runtime due to the high cost of \textsc{FindNodesByLocation}, which searches through every node for every added edge.
For this reason, it would be nice to optimize that function somehow.
\fxwarning{Do actual comparison between two ways of finding target nodes. Also mention example times from eval section at end.}

\subsection{Augmented Interval Trees}\label{subsec:kd}
To restate the problem outlined in the performance considerations \fxwarning*{Rewrite "the above" to something else, may not be above in printed version}{above:}
The locations returned by \gls{lsp} functions such as "show references" or "go to location" need to be matched to the nodes in our constructed project graph.
We cannot simply create a lookup table from locations to nodes, as the locations are not necessarily equal to the location of the nodes, even when they describe the same logical element.
Instead, we need to match the location to the node with the "tightest fitting range",
that is: from the nodes whose \gls{range} completely contains the given location, we pick the one whose \gls{range} is the smallest (to find the most specific fitting element).
The naive solution used in \cref{alg:generate}---simply going over all nodes each time to find the best fit---leads to an unacceptable runtime.

There are a few possible ways to solve this problem (which is in essence a variant of the stabbing problem) more efficiently, such as segment trees or range trees, but we will use augmented \glspl{intervaltree} with \glspl{kdtree} as a base, as this configuration best fits our circumstancesâ€”there is no need to update/re-balance the tree (so the high cost associated with that is fine), the membership query should not be in $\Omega(n)$, we need to represent two dimensions (which is possible with a 2d-tree), and so on.

A detailed explanation of augmented \glspl{intervaltree} can be found in \textcite[section~17.3]{cormen2022}, while \glspl{kdtree} are described in a paper by \textcite{bentley1975}.
In our case, we can create the tree by constructing a 2d-tree\footnote{
	Note that, in the actual implementation, the construction of the \gls{kdtree} (excluding its augmentation to an \gls{intervaltree}) is handled by the external \tt{Supercluster.KDTree} library (\web{https://github.com/ericreg/Supercluster.KDTree}{2024-10-31}).
} out of all elements (as explained in the previous sources), where the key is the starting position of the \gls{range}.
Afterwards, we save in each node the maximum line number and maximum character offset, respectively, for the subtree rooted by that node, thereby turning this \gls{kdtree} into an \gls{intervaltree}.

An updated \textsc{FindNodesByLocationEfficient} is given in \cref{alg:interval}, with these details:
\begin{itemize}
	\item An augmented \gls{intervaltree} is modeled here as a quintuple $T = (v, l, c, \lambda, \rho)$.
	      The set of all such trees is defined as $\mathcal{T}$, so $T \in \mathcal{T}$.
	      The first element $v \in V$ is the node in the project graph represented by the node in this tree.
	      The second element $l \in \mathbb{N}_0$ refers to the maximum line number across all nodes within this tree, whereas the third element $c \in \mathbb{N}_0$ analogously refers to the maximum character offset.
	      The fourth element $\lambda \in \mathcal{T}$ refers to the left subtree rooted by this node, while the fifth element $\rho \in \mathcal{T}$ conversely refers to the right subtree.
	      Taking a single element $x$ from the tuple $T$ is written as $x_T$.
	\item We construct such an augmented \gls{intervaltree} for each document (directly after part~I in \cref{alg:generate}) and save them all in a hash table $H$ (modeled as a function $H: D \rightarrow \mathcal{T}$), where each document maps to its \gls{intervaltree}.
	\item Checking whether a \gls{range} $r_1$ is contained in another \gls{range} $r_2$ is written as $r_1 \subseteq r_2$.
	\item We need a way to compare two \glspl{range} against each other to check which one is "more specific".
	      The difficulty here is that the character offsets are hard to compare to each other, since the lines can be of different lengths---handling different line lengths correctly would be both algorithmically more expensive and harder to implement, so we have given up transitivity:
	      We define a homogeneous relation $\lesssim$ on $\mathcal{R}$ that is anti-reflexive and asymmetric (but not necessarily transitive), where $r_1 \lesssim r_2$ implies that $r_1$ is more specific than $r_2$.
	      Similarly, $\simeq$ is a homogeneous relation on $\mathcal{R}$ that is reflexive and symmetric (but also not necessarily transitive), where $r_1 \simeq r_2$ if they are both "equally as specific".\footnote{
		      My actual implementation of the \texttt{CompareTo} function can be found here: \web{https://github.com/uni-bremen-agst/SEE/blob/c4e3de908a022d65723bf82d3b350dade8b5f01a/Assets/SEE/DataModel/DG/Range.cs}{2024-10-31}.
	      }
\end{itemize}

\begin{algorithm}
	\small
	\tikzexternaldisable

	\caption{Efficiently associating \gls{lsp}-returned \glspl{range} to existing elements using an already constructed augmented \gls{intervaltree}.}\label{alg:interval}
	\begin{algorithmic}[1]
		\Function{FindNodesByLocationEfficientEfficient}{$d \in D, r \in \mathcal{R}$}
		\State \Return \Call{QueryTree}{$H(d), r, \emptyset$}
		\EndFunction

		\Statex
		\Function{QueryTree}{$T \in \mathcal{T}, q \in \mathcal{R}, R \subseteq V$}
		\State $r \gets a(v_T, \tt{Source.Range})$
		\If{$b^q_l > l_T \lor (b^q_l = l_T \land b^q_c \geq c_T)$}
		\Comment{Range is to the right of all nodes in this subtree.}
		\State \Return $R$
		\EndIf
		\If{$q \subseteq r$}
		\Comment{Range is contained in this node, but we want only minimal fits.}
		\State $m \gets \{v \in R \mid r \lesssim a(v, \tt{Source.Range}) \}$
		\If{$|m| > 0$} \Comment{This range is smaller than other results.}
		\State $R \gets (R \setminus m) \cup \{v_T\}$
		\ElsIf{$\forall v \in R: a(v, \tt{Source.Range}) \simeq r$} \Comment{Other ranges are equally minimal.}
		\State $R \gets R \cup \{v_T\}$
		\EndIf
		\LComment{Otherwise, $r$ is not minimal, so we don't add the node.}
		\EndIf

		\State $R \gets \Call{QueryTree}{\lambda_T, q, R}$
		\If{$e^q_l \geq b^r_l \land (e^q_l \neq b^r_l \lor e^q_c > b^r_c))$} \Comment{Range could be contained in right subtree.}
		\State $R \gets \Call{QueryTree}{\rho_T, q, R}$
		\EndIf
		\State \Return $R$
		\EndFunction
	\end{algorithmic}
	\tikzexternalenable
\end{algorithm}
\fxwarning{So how much does it help in practice? Reference tech eval here}

\begin{codebox}[minted options={linenos,escapeinside=++,firstnumber=0}]{csharp}{lst:interval}{Example C\# source code with demarcated symbol ranges.}
+\textcolor{red}{|}+public class Example {
  +\textcolor{Emerald}{|}+const char someValue = 'A'+\textcolor{Emerald}{|}+;

  +\textcolor{Peach}{|}+public static long pow(+\textcolor{OliveGreen}{|}+int num+\textcolor{OliveGreen}{|}+) {
    +\textcolor{Brown}{|}+long result = num * num+\textcolor{Brown}{|}+;
    return result;
  }+\textcolor{Peach}{|}+
}+\textcolor{red}{|}+
\end{codebox}

As a concrete example on how this works, take a look at the example code in \cref{lst:interval}.
Here, we have the following elements:
\begin{itemize}
	\item The \tt{Example} class with range \textcolor{red}{$(0,0,7,1)$}.
	\item The \tt{someValue} field with range \textcolor{Emerald}{$(1,2,1,28)$}.
	\item The \tt{pow} method with range \textcolor{Peach}{$(3,2,6,3)$}.
	\item The \tt{num} parameter with range \textcolor{OliveGreen}{$(3,25,3,32)$}.
	\item The \tt{result} variable with range \textcolor{Brown}{$(4,4,4,27)$}.
\end{itemize}

Now, if we were to convert this into an augmented 2-d \gls{intervaltree}, it might look like \cref{fig:example_kd}.
Here, the key refers to the starting position of each element and the max value refers to the maximum line and maximum character offset in the subtree rooted by each node.
Let us say we want to find out what the range $(1,13,1,22)$ (comprising just the name of \tt{someValue}) belongs to.
We will start by checking the root node \tt{pow}:
\begin{enumerate}
	\item $b^q_l < \textcolor{Peach}{l_{\tt{pow}}}$ because $1 < \textcolor{red}{7}$, so the range is not to the right of all nodes.
	\item It is not contained by \textcolor{Peach}{\texttt{pow}}'s range.
	\item We query the left subtree $\textcolor{Peach}{\lambda_{\tt{pow}}} = \textcolor{Emerald}{\tt{someValue}}$:
	      \begin{enumerate}
		      \item $b^q_l < \textcolor{Emerald}{l_{\tt{someValue}}}$ because $1 < \textcolor{red}{7}$, so the range is not to the right of all nodes.
		      \item It is contained by \textcolor{Emerald}{\tt{someValue}}'s range, so now $R = \{\textcolor{Emerald}{v_{\tt{someValue}}}\}$.
		      \item We query the left subtree $\textcolor{Emerald}{\lambda_{\tt{someValue}}} = \textcolor{red}{\tt{Example}}$.
		            \begin{enumerate}
			            \item $b^q_l < \textcolor{red}{l_{\tt{Example}}}$ because $1 < \textcolor{red}{7}$, so the range is not to the right of all nodes.
			            \item It is contained by \textcolor{red}{\tt{Example}}'s range, but $\textcolor{red}{r_{\tt{Example}}} \gtrsim \textcolor{Emerald}{r_{\tt{someValue}}}$, so \textcolor{Emerald}{\tt{someValue}} is still the tightest fit and $R$ stays as it is.
			            \item There are no subtrees.
		            \end{enumerate}
		      \item There is no right subtree.
	      \end{enumerate}
	\item $e^q_l \ngeq \textcolor{Peach}{b^r_l}$ because $1 < \textcolor{Peach}{3}$, so there is no need to check the right subtree.
	\item Our final result is $R = \{\textcolor{Emerald}{v_{\tt{someValue}}}\}$, which is intuitively the right answer.
\end{enumerate}

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{example_kd}
	\end{center}
	\caption{An augmented \gls{intervaltree} using a \gls{kdtree}, representing the elements in \cref{lst:interval}.}\label{fig:example_kd}
\end{figure}
\fxwarning{Convert to TikZ diagram and use colors from listing!}

This new and improved \textsc{FindNodesByLocation} implementation in \cref{alg:interval} has a runtime that is in both $\Omega(1)$ and $\mathcal{O}(k + \log |V|)$, where $k$ is the number of \glspl{range} that a node is contained in---however, its worst-case runtime is still in $\mathcal{O}(|V|)$, because in the worst case, the queried range is contained in every element in the tree, meaning $k = |V|$.
Still, this case is almost impossible in real-world generated graphs.
In actuality, a given range is only going to be contained by very few elements compared to the number of total elements within a given document tree.
Taking into account that in almost all situations, $k \ll |V|$, and especially $k < \log |V|$, our average-case runtime reduces to an upper bound of $\mathcal{O}(\log |V|)$.
Hence, while the theoretical worst-case runtime complexity stays the same, the average-case runtime of \cref{alg:generate} reduces from $\Theta(|V| + n_d \cdot |V| + |E| \cdot |V|)$ to $\mathcal{O}(|V| + n_d \cdot \log |V| + |E| \cdot \log |V|)$.
Since it is easy to make mistakes here due to the inherent complexity of this part, unit tests have also been implemented to make sure both normal and edge cases are handled correctly.

\subsection{Usage in Practice}\label{subsec:alg_editor}
Now, we will have a quick look at how to actually use the algorithm in \SEE{}.
As explained before in \cref{subsec:seeother}, the \gls{lsp} importer---referring to the component responsible for using \cref{alg:generate} to generate a \gls{city}---is implemented as a \gls{provider}.
The \gls{ui} of that \gls{provider} in the \gls{editor} is shown in \cref{fig:unity_lsp_provider}.

\begin{figure}
	\begin{center}
		\includegraphics[width=0.95\textwidth]{unity_lsp_provider}
	\end{center}
	% Beware of sentences like the below, where all words except "for" and "the" are glossary terms.
	\caption{\gls{editor} \gls{ui} for the \gls{lsp} \gls{provider}}\label{fig:unity_lsp_provider}
\end{figure}

In that figure, we can see a configuration for the \tt{dcaf-rs} project\footnote{
	This is one of the sample projects we use in \cref{sec:techeval}'s technical evaluation.
}, where the \gls{ls} is the Rust Analyzer.
At the top, we can see that the path to the source project has been set, and that the \emph{Rust Analyzer}\footnote{
	The menu is grouped by language when opening it, hence the \texttt{Rust/} in front in \cref{fig:unity_lsp_provider}.
} has been selected as a \gls{ls}.
Below that, there is a field for "Source Paths".
This refers to the directories that shall be scanned for relevant documents, whereas a document's relevance is determined by its file extension.
This is distinct from the "Project Path" as that is instead used by the \gls{ls} to, for example, scan for project configuration files that describe dependencies.
Conversely, "Excluded Source Paths" can be used for those paths within the configured source paths that should be ignored (\eg, generated files, tests).

The selectable \glspl{ls} are only those that I have explicitly tested and confirmed to work with the algorithm---many servers are unusable, for example, due to required \glspl{capability} missing (such as the document symbols one).
All in all, there are working\footnote{
	There may well be more, I could not test some of the available \glspl{ls} either due to setup problems, or (like in the case of Wolfram Mathematica) because I do not have a license for the language in question.
} \glspl{ls} for the programming languages
C,
C++,
C\#,
Dart,
Go,
Haskell,
Java,
JavaScript,
Kotlin,
Lua,
MATLAB,
PHP,
Python,
Ruby,
Rust,
TypeScript,
and Zig.
There are also functioning \gls{ls} configurations for the miscellaneous languages
JSON,
\LaTeX{},
Markdown,
and XML.
A \gls{city} of a markup language like \LaTeX{}, for example, would have nodes for each section, figure, and so on, with edges representing references between these elements.

Next down the list in \cref{fig:unity_lsp_provider}, we have the import settings, which can be used to further refine the \gls{lsp}-generated data that is used for the project graph.
Specifically, we can select what kinds of nodes and edges we want to import, and which diagnostics we want to include.
Additionally, for the edges, there is the option to exclude loops and edges (excluding \tt{partOf}) to a node's direct parent.
The purpose behind this option is that otherwise, there are going to be a lot of definition/declaration edges from elements to their immediate parents, which happens because the locations returned by these \gls{lsp} functions often extend slightly outside the node's actual locations.
For example, a quirk of many \glspl{ls} is that a returned location may begin at \tt{\textcolor{red}{i}nt value;}, while the actual node for this variable starts at \tt{int \textcolor{red}{v}alue;}---in that case, the returned location would instead resolve to the outer container, such as the function it is contained in.

Finally, there is an option to enable the \gls{lsp} functions for \glspl{window} that are detailed in \cref{sec:intowindow}, a setting to generate log files for the transferred \gls{jrpc} messages, and a slider to adjust the maximum time we should wait for a \gls{ls}'s response to a request.
With all of these options configured, the graph can be loaded and drawn (and optionally exported to a \gls{gxl} file), where a bar displays the approximate progress of the process.
At this point, we will once again refer back to the explanatory video \fxnote*{Link to video again here}{TODO}, which goes over the implemented functionality in a bit more detail and may be easier to follow along than this textual description.

\section{Integrating LSP Functionality into Code Cities}\label{sec:intocity}
\fxfatal{}

% TODO: Also mention tree view here.

\section{Integrating LSP Functionality into Code Windows}\label{sec:intowindow}
\fxfatal{}

\section{Technical Evaluation}\label{sec:techeval}
\fxfatal{}

% Sample projects:
% dcaf-rs
% JabRef
% SpotBugs
% My master's thesis

\section{Interim Conclusion}
\fxfatal{}

% TODO: Mention PR for user study changes

% TODO: Reference table

\begin{table*}[htbp]
	\newcommand{\githubpr}[2]{\href{https://github.com/#1/pull/#2}{\proptt{#1\##2}}}
	\newcommand{\diffsum}[2]{\textcolor{Green}{\ensuremath{#1}} & \textcolor{Red}{\ensuremath{#2}}}
	\caption{All submitted pull requests done as part of this thesis.}\label{tab:code}
	\begin{tabular}{@{}llrl@{}}
		\toprule
		\multicolumn{1}{c}{\multirow{2}{*}{\textbf{Summary}}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Pull Request URI}}} & \multicolumn{2}{c}{\>\> $\mathbf{\Delta}$ \textbf{LOC}}                \\
		                                                      &                                                                & $\mathbf{+}$                                            & $\mathbf{-}$ \\
		\midrule
		Cleanup of \gls{lsp} specification                    & \githubpr{microsoft/language-server-protocol}{1886}            & \diffsum{475}{453}                                                     \\
		Preparing \SEE{} for \gls{lsp} integration            & \githubpr{uni-bremen-agst/SEE}{687}                            & \diffsum{282}{2773}                                                    \\
		Introducing \tt{Source.\Gls{range}}                   & \githubpr{uni-bremen-agst/SEE}{715}                            & \diffsum{392}{313}                                                     \\
		Generating \glspl{city} using \gls{lsp}               & \githubpr{uni-bremen-agst/SEE}{727}                            & \diffsum{3475}{180}                                                    \\
		\gls{lsp} functions in \glspl{city}                   & \githubpr{uni-bremen-agst/SEE}{747}                            & \diffsum{1139}{432}                                                    \\
		\gls{lsp} functions in \glspl{window}                 & \githubpr{uni-bremen-agst/SEE}{751}                            & \diffsum{4080}{2024}                                                   \\
		Preparing \SEE{} for user study                       & \githubpr{uni-bremen-agst/SEE}{772}                            & \diffsum{541}{150}                                                     \\
		\bottomrule
	\end{tabular}
	\caption*{\footnotesize Only C\# line changes have been counted in \SEE{} pull requests.\\
		GitHub pull requests are specified in the format \tt{namespace/repository\#PR\_number}.
	}

\end{table*}

